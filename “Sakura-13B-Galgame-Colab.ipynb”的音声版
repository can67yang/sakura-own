{"cells":[{"cell_type":"markdown","metadata":{"id":"Tu2Qu_P9sK-G"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isotr0py/SakuraLLM-Notebooks/blob/main/Sakura-13B-Galgame-Colab.ipynb)"]},{"cell_type":"code","source":["#@title 杀掉colab进程，会使页面报错，但是不用担心，继续运行即可，请勿跳过\n","import os\n","os.kill(os.getpid(), 9)"],"metadata":{"id":"Z6qmP3AdhKP7"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tvkI52m5DRsL","outputId":"9b6d412e-3f4a-4359-9e3d-76c54241ed52","cellView":"form","executionInfo":{"status":"ok","timestamp":1728873830862,"user_tz":-480,"elapsed":27033,"user":{"displayName":"cymhh nory","userId":"17474100186628747229"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","Mon Oct 14 02:43:48 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   63C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["#@title 初始化环境\n","#@markdown 挂载Google网盘\n","Mount_GDrive = True # @param {type:\"boolean\"}\n","if Mount_GDrive:\n","  from google.colab import drive\n","\n","  drive.mount('/content/gdrive')\n","  ROOT_PATH = \"/content/gdrive/MyDrive\"\n","else:\n","  ROOT_PATH = \"/content\"\n","!nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"gelzXVWEGxZw","colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","executionInfo":{"status":"ok","timestamp":1728874181255,"user_tz":-480,"elapsed":343228,"user":{"displayName":"cymhh nory","userId":"17474100186628747229"}},"outputId":"3a60ef76-ac31-41fc-f6ae-5e01cb4d1003"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive\n","fatal: destination path 'Sakura-13B-Galgame' already exists and is not an empty directory.\n","/content/gdrive/MyDrive/Sakura-13B-Galgame\n","remote: Enumerating objects: 26, done.\u001b[K\n","remote: Counting objects: 100% (26/26), done.\u001b[K\n","remote: Compressing objects: 100% (24/24), done.\u001b[K\n","remote: Total 24 (delta 16), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n","Unpacking objects: 100% (24/24), 8.30 KiB | 29.00 KiB/s, done.\n","From https://github.com/SakuraLLM/Sakura-13B-Galgame\n","   8c7eddb..ffe8e68  main       -> origin/main\n","Updating 8c7eddb..ffe8e68\n","Fast-forward\n"," README.md | 39 \u001b[32m+++++++++++++++++++++++++\u001b[m\u001b[31m--------------\u001b[m\n"," 1 file changed, 25 insertions(+), 14 deletions(-)\n","Collecting diskcache>=5.6.1\n","  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n","Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: diskcache\n","Successfully installed diskcache-5.6.3\n","Looking in indexes: https://abetlen.github.io/llama-cpp-python/whl/cu122\n","Collecting llama-cpp-python\n","  Downloading https://github.com/abetlen/llama-cpp-python/releases/download/v0.2.90-cu122/llama_cpp_python-0.2.90-cp310-cp310-linux_x86_64.whl (443.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.8/443.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.12.2)\n","Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.26.4)\n","Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (5.6.3)\n","Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n","Installing collected packages: llama-cpp-python\n","Successfully installed llama-cpp-python-0.2.90\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Collecting transformers\n","  Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.19.1)\n","Collecting tokenizers\n","  Downloading tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Downloading transformers-4.45.2-py3-none-any.whl (9.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tokenizers, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.19.1\n","    Uninstalling tokenizers-0.19.1:\n","      Successfully uninstalled tokenizers-0.19.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.44.2\n","    Uninstalling transformers-4.44.2:\n","      Successfully uninstalled transformers-4.44.2\n","Successfully installed tokenizers-0.20.1 transformers-4.45.2\n","Collecting vllm\n","  Downloading vllm-0.6.2-cp38-abi3-manylinux1_x86_64.whl.metadata (2.4 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from vllm) (5.9.5)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from vllm) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (1.26.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vllm) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from vllm) (4.66.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from vllm) (9.0.0)\n","Requirement already satisfied: transformers>=4.45.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (4.45.2)\n","Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.20.1)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from vllm) (3.20.3)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from vllm) (3.10.9)\n","Collecting openai>=1.40.0 (from vllm)\n","  Downloading openai-1.51.2-py3-none-any.whl.metadata (24 kB)\n","Collecting uvicorn[standard] (from vllm)\n","  Downloading uvicorn-0.31.1-py3-none-any.whl.metadata (6.6 kB)\n","Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.9.2)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from vllm) (10.4.0)\n","Requirement already satisfied: prometheus-client>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.21.0)\n","Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)\n","  Downloading prometheus_fastapi_instrumentator-7.0.0-py3-none-any.whl.metadata (13 kB)\n","Collecting tiktoken>=0.6.0 (from vllm)\n","  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Collecting lm-format-enforcer==0.10.6 (from vllm)\n","  Downloading lm_format_enforcer-0.10.6-py3-none-any.whl.metadata (16 kB)\n","Collecting outlines<0.1,>=0.0.43 (from vllm)\n","  Downloading outlines-0.0.46-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: typing-extensions>=4.10 in /usr/local/lib/python3.10/dist-packages (from vllm) (4.12.2)\n","Requirement already satisfied: filelock>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from vllm) (3.16.1)\n","Collecting partial-json-parser (from vllm)\n","  Downloading partial_json_parser-0.2.1.1.post4-py3-none-any.whl.metadata (6.2 kB)\n","Requirement already satisfied: pyzmq in /usr/local/lib/python3.10/dist-packages (from vllm) (24.0.1)\n","Collecting msgspec (from vllm)\n","  Downloading msgspec-0.18.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n","Collecting gguf==0.10.0 (from vllm)\n","  Downloading gguf-0.10.0-py3-none-any.whl.metadata (3.5 kB)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from vllm) (8.4.0)\n","Collecting mistral-common>=1.4.3 (from vllm)\n","  Downloading mistral_common-1.4.4-py3-none-any.whl.metadata (4.6 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from vllm) (6.0.2)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from vllm) (0.8.0)\n","Collecting ray>=2.9 (from vllm)\n","  Downloading ray-2.37.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (16 kB)\n","Collecting nvidia-ml-py (from vllm)\n","  Downloading nvidia_ml_py-12.560.30-py3-none-any.whl.metadata (8.6 kB)\n","Collecting torch==2.4.0 (from vllm)\n","  Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n","Collecting torchvision==0.19 (from vllm)\n","  Downloading torchvision-0.19.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.0 kB)\n","Collecting xformers==0.0.27.post2 (from vllm)\n","  Downloading xformers-0.0.27.post2-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\n","Collecting fastapi>=0.114.1 (from vllm)\n","  Downloading fastapi-0.115.2-py3-none-any.whl.metadata (27 kB)\n","Collecting interegular>=0.3.2 (from lm-format-enforcer==0.10.6->vllm)\n","  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lm-format-enforcer==0.10.6->vllm) (24.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (2024.6.1)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.0->vllm)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.0->vllm)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.0->vllm)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0->vllm)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.0->vllm)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.0->vllm)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.0->vllm)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.0->vllm)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.0->vllm)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0->vllm)\n","  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.0->vllm)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==3.0.0 (from torch==2.4.0->vllm)\n","  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0->vllm) (12.6.77)\n","Collecting starlette<0.41.0,>=0.37.2 (from fastapi>=0.114.1->vllm)\n","  Downloading starlette-0.39.2-py3-none-any.whl.metadata (6.0 kB)\n","Requirement already satisfied: jsonschema<5.0.0,>=4.21.1 in /usr/local/lib/python3.10/dist-packages (from mistral-common>=1.4.3->vllm) (4.23.0)\n","Collecting tiktoken>=0.6.0 (from vllm)\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.40.0->vllm) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.40.0->vllm) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai>=1.40.0->vllm)\n","  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n","Collecting jiter<1,>=0.4.0 (from openai>=1.40.0->vllm)\n","  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.40.0->vllm) (1.3.1)\n","Collecting lark (from outlines<0.1,>=0.0.43->vllm)\n","  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (1.6.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (2.2.1)\n","Requirement already satisfied: diskcache in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (5.6.3)\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (0.60.0)\n","Requirement already satisfied: referencing in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (0.35.1)\n","Collecting datasets (from outlines<0.1,>=0.0.43->vllm)\n","  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n","Collecting pycountry (from outlines<0.1,>=0.0.43->vllm)\n","  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n","Collecting pyairports (from outlines<0.1,>=0.0.43->vllm)\n","  Downloading pyairports-2.1.1-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9->vllm) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9->vllm) (2.23.4)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (8.1.7)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.0.8)\n","Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.3.1)\n","Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vllm) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vllm) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vllm) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vllm) (2024.8.30)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.6.0->vllm) (2024.9.11)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.19.1->vllm) (0.24.7)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.45.0->vllm) (0.4.5)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (2.4.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (24.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (1.13.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (4.0.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->vllm) (3.20.2)\n","Collecting h11>=0.8 (from uvicorn[standard]->vllm)\n","  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Collecting httptools>=0.5.0 (from uvicorn[standard]->vllm)\n","  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Collecting python-dotenv>=0.13 (from uvicorn[standard]->vllm)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]->vllm)\n","  Downloading uvloop-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting watchfiles>=0.13 (from uvicorn[standard]->vllm)\n","  Downloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting websockets>=10.4 (from uvicorn[standard]->vllm)\n","  Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.40.0->vllm) (1.2.2)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.40.0->vllm)\n","  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.21.1->mistral-common>=1.4.3->vllm) (2023.12.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.21.1->mistral-common>=1.4.3->vllm) (0.20.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (16.1.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets->outlines<0.1,>=0.0.43->vllm)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (2.2.2)\n","Collecting xxhash (from datasets->outlines<0.1,>=0.0.43->vllm)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess (from datasets->outlines<0.1,>=0.0.43->vllm)\n","  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0->vllm) (2.1.5)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->outlines<0.1,>=0.0.43->vllm) (0.43.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0->vllm) (1.3.0)\n","INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->outlines<0.1,>=0.0.43->vllm) (1.16.0)\n","Downloading vllm-0.6.2-cp38-abi3-manylinux1_x86_64.whl (228.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.3/228.3 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gguf-0.10.0-py3-none-any.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lm_format_enforcer-0.10.6-py3-none-any.whl (43 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl (797.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchvision-0.19.0-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m116.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xformers-0.0.27.post2-cp310-cp310-manylinux2014_x86_64.whl (20.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m111.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fastapi-0.115.2-py3-none-any.whl (94 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mistral_common-1.4.4-py3-none-any.whl (6.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading openai-1.51.2-py3-none-any.whl (383 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.7/383.7 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading outlines-0.0.46-py3-none-any.whl (101 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.9/101.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading prometheus_fastapi_instrumentator-7.0.0-py3-none-any.whl (19 kB)\n","Downloading ray-2.37.0-cp310-cp310-manylinux2014_x86_64.whl (65.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading msgspec-0.18.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.3/210.3 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_ml_py-12.560.30-py3-none-any.whl (40 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading partial_json_parser-0.2.1.1.post4-py3-none-any.whl (9.9 kB)\n","Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading interegular-0.3.3-py37-none-any.whl (23 kB)\n","Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Downloading starlette-0.39.2-py3-none-any.whl (73 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading uvloop-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (425 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.0.1-py3-none-any.whl (471 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lark-1.2.2-py3-none-any.whl (111 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyairports-2.1.1-py3-none-any.whl (371 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m371.7/371.7 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m115.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading uvicorn-0.31.1-py3-none-any.whl (63 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pyairports, nvidia-ml-py, xxhash, websockets, uvloop, triton, python-dotenv, pycountry, partial-json-parser, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgspec, lark, jiter, interegular, httptools, h11, gguf, dill, watchfiles, uvicorn, tiktoken, starlette, nvidia-cusolver-cu12, nvidia-cudnn-cu12, multiprocess, httpcore, torch, prometheus-fastapi-instrumentator, lm-format-enforcer, httpx, fastapi, xformers, torchvision, ray, openai, mistral-common, datasets, outlines, vllm\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.23.4\n","    Uninstalling nvidia-nccl-cu12-2.23.4:\n","      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n","    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n","    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n","      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n","    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n","    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n","    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n","      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n","    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.4.0.58\n","    Uninstalling nvidia-cudnn-cu12-9.4.0.58:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.4.0.58\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.4.1+cu121\n","    Uninstalling torch-2.4.1+cu121:\n","      Successfully uninstalled torch-2.4.1+cu121\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.19.1+cu121\n","    Uninstalling torchvision-0.19.1+cu121:\n","      Successfully uninstalled torchvision-0.19.1+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.4.1+cu121 requires torch==2.4.1, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.0.1 dill-0.3.8 fastapi-0.115.2 gguf-0.10.0 h11-0.14.0 httpcore-1.0.6 httptools-0.6.1 httpx-0.27.2 interegular-0.3.3 jiter-0.6.1 lark-1.2.2 lm-format-enforcer-0.10.6 mistral-common-1.4.4 msgspec-0.18.6 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-ml-py-12.560.30 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 openai-1.51.2 outlines-0.0.46 partial-json-parser-0.2.1.1.post4 prometheus-fastapi-instrumentator-7.0.0 pyairports-2.1.1 pycountry-24.6.1 python-dotenv-1.0.1 ray-2.37.0 starlette-0.39.2 tiktoken-0.7.0 torch-2.4.0 torchvision-0.19.0 triton-3.0.0 uvicorn-0.31.1 uvloop-0.20.0 vllm-0.6.2 watchfiles-0.24.0 websockets-13.1 xformers-0.0.27.post2 xxhash-3.5.0\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","vllm 0.6.2 requires tokenizers>=0.19.1, but you have tokenizers 0.13.3 which is incompatible.\n","vllm 0.6.2 requires transformers>=4.45.0, but you have transformers 4.33.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["#@title 安装依赖\n","%cd $ROOT_PATH\n","!git clone https://github.com/SakuraLLM/Sakura-13B-Galgame.git\n","\n","%cd Sakura-13B-Galgame\n","!git pull\n","\n","LLAMA_CPP = True # @param {type:\"boolean\"}\n","VLLM = True # @param {type:\"boolean\"}\n","if LLAMA_CPP:\n","  !pip install \"diskcache>=5.6.1\"\n","  !pip install llama-cpp-python -i https://abetlen.github.io/llama-cpp-python/whl/cu122\n","if VLLM:\n","  !pip install -U transformers tokenizers\n","  !pip install vllm\n","!pip install -q -r requirements.txt\n","!pip install -q pyngrok"]},{"cell_type":"code","source":["#@title 调用api\n","from huggingface_hub import hf_hub_download\n","from pyngrok import ngrok\n","\n","# 设置 ngrok authtoken（替换 <YOUR_AUTH_TOKEN> 为你的实际 ngrok authtoken）\n","!ngrok authtoken 2aD0E5ADxy6miRBapzrwWTOu3j6_3Phqsv4LxCQwu7iVuxYgT\n","\n","# 启动 ngrok 隧道并连接到本地端口 8080\n","public_url = ngrok.connect(8181)\n","print(\"ngrok tunnel URL:\", public_url)\n","\n","repo_id = \"SakuraLLM/Sakura-14B-Qwen2.5-v1.0-GGUF\"\n","MODEL = \"sakura-14b-qwen2.5-v1.0-iq4xs.gguf\" # @param [\"sakura-14b-qwen2beta-v0.9.2-iq4xs.gguf\", \"sakura-14b-qwen2beta-v0.9.2-q2k.gguf\", \"sakura-14b-qwen2beta-v0.9.2-q3km.gguf\", \"sakura-14b-qwen2beta-v0.9.2-q4km.gguf\", \"sakura-14b-qwen2beta-v0.9.2-q6k.gguf\",\"sakura-14b-qwen2.5-v1.0-iq4xs.gguf\"]\n","hf_hub_download(repo_id=repo_id, filename=MODEL, local_dir=\"models/\")\n","MODEL_PATH = f\"./models/{MODEL}\"\n","\n","%cd $ROOT_PATH/Sakura-13B-Galgame\n","!python server.py \\\n","    --model_name_or_path $MODEL_PATH \\\n","    --llama_cpp \\\n","    --use_gpu \\\n","    --model_version 0.9 \\\n","    --trust_remote_code \\\n","    --no-auth \\\n","    --listen localhost:8181\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["ec033522552e415eaf87df12de29c6fe","638be34d74e84a04a38e26cad1b7e1a7","7cfa9c1029a34a8fbf6fa7ad8b1c9c73","0a77d7d559a74321978a5978a783aabd","f96562bd63824eb0acbd627714f3e7f1","865133b617a24f67a5228e7fa1f35b39","770337bb59e84bd89ee3f7691c03ec86","4be1702e36db4b29a9d592237a3429ff","5dad1d7db0504a379e1a258bc885a3ce","4999120da8bf484a80c278a7fe240721","629e4d4cbf584661bd43f78ab1200b42"]},"id":"ym4mofxfDaGN","outputId":"62db3919-3e85-4330-bc7c-00047af46d9f","executionInfo":{"status":"ok","timestamp":1728875271517,"user_tz":-480,"elapsed":725584,"user":{"displayName":"cymhh nory","userId":"17474100186628747229"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n","ngrok tunnel URL: NgrokTunnel: \"https://b1b7-34-32-252-14.ngrok-free.app\" -> \"http://localhost:8181\"\n"]},{"output_type":"display_data","data":{"text/plain":["sakura-14b-qwen2.5-v1.0-iq4xs.gguf:  46%|####6     | 3.79G/8.19G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec033522552e415eaf87df12de29c6fe"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/Sakura-13B-Galgame\n","\u001b[32m2024-10-14 02:56:27\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34m__main__[4104]\u001b[0m \u001b[1;30mWARNING\u001b[0m \u001b[33mAuth is disabled!\u001b[0m\n","\u001b[32m2024-10-14 02:56:32\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34m__main__[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Current server config: Server(listen: localhost:8181, auth: None:None)\n","\u001b[32m2024-10-14 02:56:32\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34m__main__[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Current model config: SakuraModelConfig(model_name_or_path='./models/sakura-14b-qwen2.5-v1.0-iq4xs.gguf', use_gptq_model=False, use_awq_model=False, trust_remote_code=True, text_length=512, llama=False, llama_cpp=True, use_gpu=True, n_gpu_layers=0, vllm=False, enforce_eager=False, tensor_parallel_size=1, gpu_memory_utilization=0.9, ollama=False, model_name=None, model_quant=None, model_version='0.9')\n","2024-10-14 02:56:36.413301: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-10-14 02:56:36.905378: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-10-14 02:56:37.021104: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-10-14 02:56:42.420720: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[32m2024-10-14 02:56:45\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mnumexpr.utils[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m NumExpr defaulting to 2 threads.\n","/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n","  torch.utils._pytree._register_pytree_node(\n","\u001b[32m2024-10-14 02:56:45\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mutils.model[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m loading model ...\n","llama_model_loader: loaded meta data with 27 key-value pairs and 579 tensors from ./models/sakura-14b-qwen2.5-v1.0-iq4xs.gguf (version GGUF V3 (latest))\n","llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n","llama_model_loader: - kv   0:                       general.architecture str              = qwen2\n","llama_model_loader: - kv   1:                               general.type str              = model\n","llama_model_loader: - kv   2:                               general.name str              = sakura-14b-qwen2.5-v1.0-iq4xs\n","llama_model_loader: - kv   3:                            general.version str              = 1008\n","llama_model_loader: - kv   4:                           general.finetune str              = qwen2.5-sft-part1\n","llama_model_loader: - kv   5:                           general.basename str              = sakura\n","llama_model_loader: - kv   6:                         general.size_label str              = 14B\n","llama_model_loader: - kv   7:                          qwen2.block_count u32              = 48\n","llama_model_loader: - kv   8:                       qwen2.context_length u32              = 131072\n","llama_model_loader: - kv   9:                     qwen2.embedding_length u32              = 5120\n","llama_model_loader: - kv  10:                  qwen2.feed_forward_length u32              = 13824\n","llama_model_loader: - kv  11:                 qwen2.attention.head_count u32              = 40\n","llama_model_loader: - kv  12:              qwen2.attention.head_count_kv u32              = 8\n","llama_model_loader: - kv  13:                       qwen2.rope.freq_base f32              = 1000000.000000\n","llama_model_loader: - kv  14:     qwen2.attention.layer_norm_rms_epsilon f32              = 0.000010\n","llama_model_loader: - kv  15:                          general.file_type u32              = 30\n","llama_model_loader: - kv  16:                       tokenizer.ggml.model str              = gpt2\n","llama_model_loader: - kv  17:                         tokenizer.ggml.pre str              = qwen2\n","llama_model_loader: - kv  18:                      tokenizer.ggml.tokens arr[str,152064]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n","llama_model_loader: - kv  19:                  tokenizer.ggml.token_type arr[i32,152064]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n","llama_model_loader: - kv  20:                      tokenizer.ggml.merges arr[str,151387]  = [\"Ġ Ġ\", \"ĠĠ ĠĠ\", \"i n\", \"Ġ t\",...\n","llama_model_loader: - kv  21:                tokenizer.ggml.eos_token_id u32              = 151643\n","llama_model_loader: - kv  22:            tokenizer.ggml.padding_token_id u32              = 151643\n","llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 151643\n","llama_model_loader: - kv  24:               tokenizer.ggml.add_bos_token bool             = false\n","llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {%- if tools %}\\n    {{- '<|im_start|>...\n","llama_model_loader: - kv  26:               general.quantization_version u32              = 2\n","llama_model_loader: - type  f32:  241 tensors\n","llama_model_loader: - type q5_K:   54 tensors\n","llama_model_loader: - type q6_K:    1 tensors\n","llama_model_loader: - type iq4_xs:  283 tensors\n","llm_load_vocab: special tokens cache size = 22\n","llm_load_vocab: token to piece cache size = 0.9310 MB\n","llm_load_print_meta: format           = GGUF V3 (latest)\n","llm_load_print_meta: arch             = qwen2\n","llm_load_print_meta: vocab type       = BPE\n","llm_load_print_meta: n_vocab          = 152064\n","llm_load_print_meta: n_merges         = 151387\n","llm_load_print_meta: vocab_only       = 0\n","llm_load_print_meta: n_ctx_train      = 131072\n","llm_load_print_meta: n_embd           = 5120\n","llm_load_print_meta: n_layer          = 48\n","llm_load_print_meta: n_head           = 40\n","llm_load_print_meta: n_head_kv        = 8\n","llm_load_print_meta: n_rot            = 128\n","llm_load_print_meta: n_swa            = 0\n","llm_load_print_meta: n_embd_head_k    = 128\n","llm_load_print_meta: n_embd_head_v    = 128\n","llm_load_print_meta: n_gqa            = 5\n","llm_load_print_meta: n_embd_k_gqa     = 1024\n","llm_load_print_meta: n_embd_v_gqa     = 1024\n","llm_load_print_meta: f_norm_eps       = 0.0e+00\n","llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n","llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n","llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n","llm_load_print_meta: f_logit_scale    = 0.0e+00\n","llm_load_print_meta: n_ff             = 13824\n","llm_load_print_meta: n_expert         = 0\n","llm_load_print_meta: n_expert_used    = 0\n","llm_load_print_meta: causal attn      = 1\n","llm_load_print_meta: pooling type     = 0\n","llm_load_print_meta: rope type        = 2\n","llm_load_print_meta: rope scaling     = linear\n","llm_load_print_meta: freq_base_train  = 1000000.0\n","llm_load_print_meta: freq_scale_train = 1\n","llm_load_print_meta: n_ctx_orig_yarn  = 131072\n","llm_load_print_meta: rope_finetuned   = unknown\n","llm_load_print_meta: ssm_d_conv       = 0\n","llm_load_print_meta: ssm_d_inner      = 0\n","llm_load_print_meta: ssm_d_state      = 0\n","llm_load_print_meta: ssm_dt_rank      = 0\n","llm_load_print_meta: ssm_dt_b_c_rms   = 0\n","llm_load_print_meta: model type       = ?B\n","llm_load_print_meta: model ftype      = IQ4_XS - 4.25 bpw\n","llm_load_print_meta: model params     = 14.77 B\n","llm_load_print_meta: model size       = 7.62 GiB (4.43 BPW) \n","llm_load_print_meta: general.name     = sakura-14b-qwen2.5-v1.0-iq4xs\n","llm_load_print_meta: BOS token        = 151643 '<|endoftext|>'\n","llm_load_print_meta: EOS token        = 151643 '<|endoftext|>'\n","llm_load_print_meta: PAD token        = 151643 '<|endoftext|>'\n","llm_load_print_meta: LF token         = 148848 'ÄĬ'\n","llm_load_print_meta: EOT token        = 151645 '<|im_end|>'\n","llm_load_print_meta: max token length = 256\n","ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    yes\n","ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n","ggml_cuda_init: found 1 CUDA devices:\n","  Device 0: Tesla T4, compute capability 7.5, VMM: yes\n","llm_load_tensors: ggml ctx size =    0.51 MiB\n","llm_load_tensors: offloading 48 repeating layers to GPU\n","llm_load_tensors: offloading non-repeating layers to GPU\n","llm_load_tensors: offloaded 49/49 layers to GPU\n","llm_load_tensors:        CPU buffer size =   394.45 MiB\n","llm_load_tensors:      CUDA0 buffer size =  7406.82 MiB\n","..........................................................................................\n","llama_new_context_with_model: n_ctx      = 2048\n","llama_new_context_with_model: n_batch    = 512\n","llama_new_context_with_model: n_ubatch   = 512\n","llama_new_context_with_model: flash_attn = 0\n","llama_new_context_with_model: freq_base  = 1000000.0\n","llama_new_context_with_model: freq_scale = 1\n","llama_kv_cache_init:      CUDA0 KV buffer size =   384.00 MiB\n","llama_new_context_with_model: KV self size  =  384.00 MiB, K (f16):  192.00 MiB, V (f16):  192.00 MiB\n","llama_new_context_with_model:  CUDA_Host  output buffer size =     0.58 MiB\n","llama_new_context_with_model:      CUDA0 compute buffer size =   307.00 MiB\n","llama_new_context_with_model:  CUDA_Host compute buffer size =    14.01 MiB\n","llama_new_context_with_model: graph nodes  = 1686\n","llama_new_context_with_model: graph splits = 2\n","AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n","Model metadata: {'tokenizer.ggml.add_bos_token': 'false', 'tokenizer.ggml.bos_token_id': '151643', 'general.file_type': '30', 'qwen2.attention.layer_norm_rms_epsilon': '0.000010', 'tokenizer.ggml.eos_token_id': '151643', 'qwen2.rope.freq_base': '1000000.000000', 'general.architecture': 'qwen2', 'tokenizer.ggml.padding_token_id': '151643', 'general.basename': 'sakura', 'qwen2.embedding_length': '5120', 'tokenizer.ggml.pre': 'qwen2', 'general.name': 'sakura-14b-qwen2.5-v1.0-iq4xs', 'qwen2.block_count': '48', 'general.version': '1008', 'general.finetune': 'qwen2.5-sft-part1', 'general.type': 'model', 'general.size_label': '14B', 'qwen2.context_length': '131072', 'tokenizer.chat_template': '{%- if tools %}\\n    {{- \\'<|im_start|>system\\\\n\\' }}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- messages[0][\\'content\\'] }}\\n    {%- else %}\\n        {{- \\'You are a helpful assistant.\\' }}\\n    {%- endif %}\\n    {{- \"\\\\n\\\\n# Tools\\\\n\\\\nYou may call one or more functions to assist with the user query.\\\\n\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\" }}\\n    {%- for tool in tools %}\\n        {{- \"\\\\n\" }}\\n        {{- tool | tojson }}\\n    {%- endfor %}\\n    {{- \"\\\\n</tools>\\\\n\\\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\\\n<tool_call>\\\\n{\\\\\"name\\\\\": <function-name>, \\\\\"arguments\\\\\": <args-json-object>}\\\\n</tool_call><|im_end|>\\\\n\" }}\\n{%- else %}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- \\'<|im_start|>system\\\\n\\' + messages[0][\\'content\\'] + \\'<|im_end|>\\\\n\\' }}\\n    {%- else %}\\n        {{- \\'<|im_start|>system\\\\nYou are a helpful assistant.<|im_end|>\\\\n\\' }}\\n    {%- endif %}\\n{%- endif %}\\n{%- for message in messages %}\\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\\n        {{- \\'<|im_start|>\\' + message.role + \\'\\\\n\\' + message.content + \\'<|im_end|>\\' + \\'\\\\n\\' }}\\n    {%- elif message.role == \"assistant\" %}\\n        {{- \\'<|im_start|>\\' + message.role }}\\n        {%- if message.content %}\\n            {{- \\'\\\\n\\' + message.content }}\\n        {%- endif %}\\n        {%- for tool_call in message.tool_calls %}\\n            {%- if tool_call.function is defined %}\\n                {%- set tool_call = tool_call.function %}\\n            {%- endif %}\\n            {{- \\'\\\\n<tool_call>\\\\n{\"name\": \"\\' }}\\n            {{- tool_call.name }}\\n            {{- \\'\", \"arguments\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \\'}\\\\n</tool_call>\\' }}\\n        {%- endfor %}\\n        {{- \\'<|im_end|>\\\\n\\' }}\\n    {%- elif message.role == \"tool\" %}\\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\\n            {{- \\'<|im_start|>user\\' }}\\n        {%- endif %}\\n        {{- \\'\\\\n<tool_response>\\\\n\\' }}\\n        {{- message.content }}\\n        {{- \\'\\\\n</tool_response>\\' }}\\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\\n            {{- \\'<|im_end|>\\\\n\\' }}\\n        {%- endif %}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|im_start|>assistant\\\\n\\' }}\\n{%- endif %}\\n', 'qwen2.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'qwen2.feed_forward_length': '13824', 'qwen2.attention.head_count': '40'}\n","Available chat formats from metadata: chat_template.default\n","Using gguf chat template: {%- if tools %}\n","    {{- '<|im_start|>system\\n' }}\n","    {%- if messages[0]['role'] == 'system' %}\n","        {{- messages[0]['content'] }}\n","    {%- else %}\n","        {{- 'You are a helpful assistant.' }}\n","    {%- endif %}\n","    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n","    {%- for tool in tools %}\n","        {{- \"\\n\" }}\n","        {{- tool | tojson }}\n","    {%- endfor %}\n","    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n","{%- else %}\n","    {%- if messages[0]['role'] == 'system' %}\n","        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n","    {%- else %}\n","        {{- '<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n' }}\n","    {%- endif %}\n","{%- endif %}\n","{%- for message in messages %}\n","    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\n","        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n","    {%- elif message.role == \"assistant\" %}\n","        {{- '<|im_start|>' + message.role }}\n","        {%- if message.content %}\n","            {{- '\\n' + message.content }}\n","        {%- endif %}\n","        {%- for tool_call in message.tool_calls %}\n","            {%- if tool_call.function is defined %}\n","                {%- set tool_call = tool_call.function %}\n","            {%- endif %}\n","            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n","            {{- tool_call.name }}\n","            {{- '\", \"arguments\": ' }}\n","            {{- tool_call.arguments | tojson }}\n","            {{- '}\\n</tool_call>' }}\n","        {%- endfor %}\n","        {{- '<|im_end|>\\n' }}\n","    {%- elif message.role == \"tool\" %}\n","        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n","            {{- '<|im_start|>user' }}\n","        {%- endif %}\n","        {{- '\\n<tool_response>\\n' }}\n","        {{- message.content }}\n","        {{- '\\n</tool_response>' }}\n","        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n","            {{- '<|im_end|>\\n' }}\n","        {%- endif %}\n","    {%- endif %}\n","{%- endfor %}\n","{%- if add_generation_prompt %}\n","    {{- '<|im_start|>assistant\\n' }}\n","{%- endif %}\n","\n","Using chat eos_token: <|endoftext|>\n","Using chat bos_token: <|endoftext|>\n","\n","llama_print_timings:        load time =    1268.44 ms\n","llama_print_timings:      sample time =       1.65 ms /     7 runs   (    0.24 ms per token,  4239.85 tokens per second)\n","llama_print_timings: prompt eval time =    1268.31 ms /    76 tokens (   16.69 ms per token,    59.92 tokens per second)\n","llama_print_timings:        eval time =     404.17 ms /     6 runs   (   67.36 ms per token,    14.85 tokens per second)\n","llama_print_timings:       total time =    1707.26 ms /    82 tokens\n","{'choices': [{'finish_reason': 'stop',\n","              'index': 0,\n","              'logprobs': None,\n","              'text': '干劲满满的外皮。'}],\n"," 'created': 1728874646,\n"," 'id': 'cmpl-5e07770e-544b-4eb6-907a-afebfdd942cb',\n"," 'model': './models/sakura-14b-qwen2.5-v1.0-iq4xs.gguf',\n"," 'object': 'text_completion',\n"," 'usage': {'completion_tokens': 6, 'prompt_tokens': 76, 'total_tokens': 82}}\n","\u001b[32m2024-10-14 02:57:28\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mroot[4104]\u001b[0m \u001b[1;30mWARNING\u001b[0m \u001b[33mmodel output is not correct, please check the loaded model\u001b[0m\n","\u001b[32m2024-10-14 02:57:28\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mroot[4104]\u001b[0m \u001b[1;30mWARNING\u001b[0m \u001b[33minput: <|im_start|>system\n","你是一个轻小说翻译模型，可以流畅通顺地以日本轻小说的风格将日文翻译成简体中文，并联系上下文正确使用人称代词，不擅自添加原文中没有的代词。<|im_end|>\n","<|im_start|>user\n","将下面的日文文本翻译成中文：やる気マンゴスキン<|im_end|>\n","<|im_start|>assistant\n","\u001b[0m\n","\u001b[32m2024-10-14 02:57:28\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mroot[4104]\u001b[0m \u001b[1;30mWARNING\u001b[0m \u001b[33mground_truth: 干劲Mangoskin\u001b[0m\n","\u001b[32m2024-10-14 02:57:28\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mroot[4104]\u001b[0m \u001b[1;30mWARNING\u001b[0m \u001b[33mcurrent output: prompt_token=76 new_token=6 text='干劲满满的外皮。' finish_reason='stop'\u001b[0m\n","\u001b[32m2024-10-14 02:57:28\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34m__main__[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Server will run at http://localhost:8181, preparing...\n","[2024-10-14 02:57:28 +0000] [4104] [INFO] Running on http://127.0.0.1:8181 (CTRL + C to quit)\n","\u001b[32m2024-10-14 02:57:28\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mhypercorn.error[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Running on http://127.0.0.1:8181 (CTRL + C to quit)\n","\u001b[32m2024-10-14 02:58:25\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Incoming request api: http://b1b7-34-32-252-14.ngrok-free.app/v1/chat/completions\n","\u001b[32m2024-10-14 02:58:25\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m client: Address(host='127.0.0.1', port=54268)\n","\u001b[32m2024-10-14 02:58:25\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m translate: <|im_start|>system\n","You are a highly skilled translation engine with expertise in eBook translation. Your function is to translate eBook texts accurately into the Simplified Chinese Language, maintaining the original tone, style, and formatting. Focus on delivering translations that resonate with the intended audience while ensuring the essence of the original text is preserved.<|im_end|>\n","<|im_start|>user\n","Translate the following source text to Simplified Chinese Language, Output translation directly without any additional text.\n","Source Text: Hello world\n","Translated Text:<|im_end|>\n","<|im_start|>assistant\n","\n","Llama.generate: 3 prefix-match hit, remaining 97 prompt tokens to eval\n","\n","llama_print_timings:        load time =    1268.44 ms\n","llama_print_timings:      sample time =       1.60 ms /     8 runs   (    0.20 ms per token,  4984.42 tokens per second)\n","llama_print_timings: prompt eval time =     473.69 ms /    97 tokens (    4.88 ms per token,   204.78 tokens per second)\n","llama_print_timings:        eval time =     406.26 ms /     7 runs   (   58.04 ms per token,    17.23 tokens per second)\n","llama_print_timings:       total time =     908.83 ms /   104 tokens\n","{'choices': [{'finish_reason': 'stop',\n","              'index': 0,\n","              'logprobs': None,\n","              'text': '你好，世界\\n你好，世界'}],\n"," 'created': 1728874705,\n"," 'id': 'cmpl-d895ca4c-28a9-4796-9c58-383b51c57cee',\n"," 'model': './models/sakura-14b-qwen2.5-v1.0-iq4xs.gguf',\n"," 'object': 'text_completion',\n"," 'usage': {'completion_tokens': 7, 'prompt_tokens': 100, 'total_tokens': 107}}\n","\u001b[32m2024-10-14 02:58:26\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mutils.model[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Output generated in 0.92 seconds (7.59 tokens/s, 7 tokens, context 100 tokens)\n","\u001b[32m2024-10-14 02:58:26\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m answer: prompt_token=100 new_token=7 text='你好，世界\\n你好，世界' finish_reason='stop'\n","\u001b[32m2024-10-14 02:58:59\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Incoming request api: http://b1b7-34-32-252-14.ngrok-free.app/v1/chat/completions\n","\u001b[32m2024-10-14 02:58:59\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m client: Address(host='127.0.0.1', port=46734)\n","\u001b[32m2024-10-14 02:58:59\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m translate: <|im_start|>system\n","You are a highly skilled translation engine with expertise in eBook translation. Your function is to translate eBook texts accurately into the Simplified Chinese Language, maintaining the original tone, style, and formatting. Focus on delivering translations that resonate with the intended audience while ensuring the essence of the original text is preserved.<|im_end|>\n","<|im_start|>user\n","Translate the following source text to Simplified Chinese Language, Output translation directly without any additional text.\n","Source Text: ● 蝉 の 声 ︒ 坂 道 を 降 り る ⾜ ⾳ ★ 左 斜 め 前 ▲ 中 距 離 ■ 驚 い て 咄 嗟 に 先 ︑ ⽣ … ？ ● 近 づ い て く る ⾜ ⾳ ★ 左 斜 め 前 ▲ 通 常 ■ 少 し 興 奮 気 味 で 嬉 し そ う に お 久 し ぶ り で す ︒ 先 ⽣ ★ 左 斜 め 前 ▲ 通 常 ↓ ︵ 移 動 ︶ ★ 正 ⾯ ▲ 通 常 ■ 微 笑 し な が ら ど う し た ん で す か ？ そ の 顔 ま さ か … 私 の こ と ︑ 忘 れ ち た ん で す か ？ ■ 嬉 し そ う に 雁 夜 で す ︒ 雁 夜 千 織 ⾼ 校 の 時 以 来 で す か ら … 五 年 ぶ り く ら い で す か ね ？ ほ ら 美 術 部 で 絵 を 教 え て く だ さ た じ な い で す か ■ 思 い 出 し て も ら え て 満 ⾜ そ う に え え ︑ え え … ■ ほ と 気 が 緩 ん だ 様 ⼦ で や と 思 い 出 し て く れ ま し た か 私 ︑ こ の 近 く に 住 ん で い る ん で す ⼤ 学 か ら 近 い の で ■ 様 ⼦ を 伺 う 感 じ で そ の 展 ⽰ 案 内 … も し か し て う ち の ⼤ 学 の 展 ⽰ ︑ ⾒ に ⾏ か れ た ん で す か ？ ■ 尊 敬 の 眼 差 し で や ぱ り … 流 ⽯ は 美 術 教 師 で す ね ■ 期 待 し て 嬉 し そ う に 来 年 は 私 も 展 ⽰ す る の で 是 ⾮ い ら し て く だ さ い ■ 得 意 気 に ふ ふ ︑ そ う で す よ こ れ で も ち ん と 芸 ⼤ 三 回 ⽣ で す か ら ■ 嬉 し そ う に 先 ⽣ が 絵 を 教 え て く だ さ た お か げ で す ■ 思 い つ い た 様 ⼦ で そ う だ ︑ こ ん な と こ ろ で ⽴ ち 話 も 何 で す し ア ト リ エ に い ら し て く れ ま せ ん か ？\n","Translated Text:<|im_end|>\n","<|im_start|>assistant\n","\n","Llama.generate: 89 prefix-match hit, remaining 941 prompt tokens to eval\n","\u001b[32m2024-10-14 02:58:59\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Incoming request api: http://b1b7-34-32-252-14.ngrok-free.app/v1/chat/completions\n","\u001b[32m2024-10-14 02:58:59\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m client: Address(host='127.0.0.1', port=46736)\n","\u001b[32m2024-10-14 02:58:59\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Incoming request api: http://b1b7-34-32-252-14.ngrok-free.app/v1/chat/completions\n","\u001b[32m2024-10-14 02:58:59\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m client: Address(host='127.0.0.1', port=46744)\n","\u001b[32m2024-10-14 02:58:59\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Incoming request api: http://b1b7-34-32-252-14.ngrok-free.app/v1/chat/completions\n","\u001b[32m2024-10-14 02:58:59\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m client: Address(host='127.0.0.1', port=46750)\n","\u001b[32m2024-10-14 02:58:59\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m translate: <|im_start|>system\n","You are a highly skilled translation engine with expertise in eBook translation. Your function is to translate eBook texts accurately into the Simplified Chinese Language, maintaining the original tone, style, and formatting. Focus on delivering translations that resonate with the intended audience while ensuring the essence of the original text is preserved.<|im_end|>\n","<|im_start|>user\n","Translate the following source text to Simplified Chinese Language, Output translation directly without any additional text.\n","Source Text: ■ 気 遣 う 様 ⼦ で 先 ⽣ ︑ 喘 息 も あ り ま す し 体 強 く な い ん で す か ら … ● 主 ⼈ 公 の 返 答 イ メ ジ ﹁ よ く 覚 え て え る ね … ︒ 確 か に 今 ⽇ も 暑 い し ︑ そ の ⽅ が い い か も ね ﹂ ■ 相 槌 は い … ■ 優 し く 誘 う イ メ ジ こ こ か ら 歩 い て 直 ぐ で す 冷 た い ⻨ 茶 も あ り ま す よ ■ 少 し い じ ら し そ う に そ れ に … 私 ︑ 先 ⽣ に ま た 絵 を ⾒ て も ら い た い で す ■ 嬉 し そ う に あ は … あ り が と う ご ざ い ま す で は ︑ ご 案 内 い た し ま す ね ● ⾜ ⾳ ★ 左 ▲ 通 常 ■ 微 笑 し な が ら 今 ⽇ も 暑 い で す ね 夏 だ か ら 仕 ⽅ な い ん で す け ど ■ 楽 し そ う に そ う だ ︑ 美 術 部 は ど う で す か ？ ■ 少 し 得 意 気 で 会 話 を 盛 り 上 げ よ う と 冗 談 混 じ り に 私 の 後 輩 に な り そ う な ︑ 優 秀 で 才 能 溢 れ る ⼦ は い ま す か ？ ふ ふ … そ り ⼀ 年 浪 ⼈ と は い え 芸 ⼤ 合 格 し て ま す し ？ 少 し く ら い ⾃ 慢 し た い じ な い で す か ■ 驚 い て シ ク を 受 け る え … 美 術 部 無 く な ち た ん で す か ？ そ う … で す か ■ 驚 愕 し た 様 ⼦ で え … 美 術 の 授 業 も 無 く な る ん で す か ？ じ あ ︑ 先 ⽣ は … ■ 唖 然 と し て 転 任 て … そ ん な … ■ 意 気 消 沈 …… ︒ ■ 静 か に ⾃ ら を 納 得 さ せ る よ う に 元 々 ⾳ 楽 と 選 択 制 で し た も ん ね ■ 寂 し そ う に … そ う か … 今 は そ ん な 感 じ な ん で す ね 美 術 の 授 業 ま で 無 く な る と は … … ︑ ⾊ 々 変 わ ち う も の で す ね ■ 苦 笑 い し て あ は は ︑ な ん か し ん み り し ち い ま し た ね ■ 話 題 を 変 え よ う と ち と ぎ こ ち な く そ う い え ば 私 の こ と ︑ 本 当 に 誰 だ か わ か ら な か た ん で す か ？\n","Translated Text:<|im_end|>\n","<|im_start|>assistant\n","\n","\u001b[32m2024-10-14 02:58:59\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m translate: <|im_start|>system\n","You are a highly skilled translation engine with expertise in eBook translation. Your function is to translate eBook texts accurately into the Simplified Chinese Language, maintaining the original tone, style, and formatting. Focus on delivering translations that resonate with the intended audience while ensuring the essence of the original text is preserved.<|im_end|>\n","<|im_start|>user\n","Translate the following source text to Simplified Chinese Language, Output translation directly without any additional text.\n","Source Text: ま ︑ 呼 び ⽅ は ど う で も い い で す ね ■ 楽 し そ う に 普 段 は こ こ に 座 て こ の イ ゼ ル に キ ン バ ス を ⽴ て て 描 い て い ま す 素 敵 で す よ ね ？ ■ 嬉 し そ う に う ふ ふ ︑ よ か た … 気 に い て も ら え て ■ ハ と し た 様 ⼦ で あ … 飲 み 物 忘 れ て ま し た ■ 申 し 訳 な さ そ う に ご め ん な さ い … ⼈ が 来 る こ と が 滅 多 に な い も の で す か ら ■ そ わ そ わ し た 様 ⼦ で 嬉 し そ う に 期 待 し て そ う だ … ︑ 私 も う 成 ⼈ し て る の で お 酒 飲 め る よ う に な た ん で す よ ■ い じ ら し い 様 ⼦ で 少 し 早 い 時 間 で す け ど ⼀ 緒 に ど う で す か ？ ■ し み じ み と 胸 の 内 を 吐 露 す る 私 … 昔 の 思 い 出 話 を し な が ら ⼀ 杯 や る の が 夢 だ た ん で す ■ い じ ら し い 様 ⼦ で 付 き 合 て … く れ ま せ ん か ？ ■ 嬉 し そ う に あ り が と う ご ざ い ま す … ● 時 間 経 過 ★ 正 ⾯ ▲ 通 常 ■ 楽 し そ う に そ れ で 美 術 室 の 鍵 … 結 局 先 ⽣ の ポ ケ ト に ⼊ て た ん で す よ ね ■ 頬 を 膨 ら ま せ る 感 じ で ︑ 可 愛 く 怒 る ⼤ 変 だ た ん で す よ ？ 鍵 が 無 く て 施 錠 で き な い と 帰 れ な い の で ︑ 焦 り ま し た … ■ 嬉 し そ う に ま ︑ 今 と な て は い い 思 い 出 で す ■ お 酒 を 飲 む ご く … ご く ︑ ご く ︑ は … ■ し み じ み と 先 ⽣ に 絵 を ご 指 導 い た だ い た 三 年 間 … 本 当 に ⼤ 切 な ︑ か え が え の な い ⽇ 々 で し た ■ 少 し 申 し 訳 な さ そ う に そ う だ ︑ ま た 私 の 絵 を ⾒ て い た だ け な い で し う か ？\n","Translated Text:<|im_end|>\n","<|im_start|>assistant\n","\n","\u001b[32m2024-10-14 02:58:59\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m translate: <|im_start|>system\n","You are a highly skilled translation engine with expertise in eBook translation. Your function is to translate eBook texts accurately into the Simplified Chinese Language, maintaining the original tone, style, and formatting. Focus on delivering translations that resonate with the intended audience while ensuring the essence of the original text is preserved.<|im_end|>\n","<|im_start|>user\n","Translate the following source text to Simplified Chinese Language, Output translation directly without any additional text.\n","Source Text: ● ⾜ を ⽌ め る ■ 嘆 息 ふ ん … ★ 正 ⾯ ▲ 通 常 ■ ⼝ 元 に ⼈ 差 し 指 を 当 て て ︑ 静 か に 諭 す よ う に ︒ こ こ の 台 詞 だ け ミ ス テ リ ア ス に 先 ⽣ ⼥ の ⼦ は 変 わ る ん で す よ も う ⼆ ⼗ 歳 な ん で す か ら ︑ ⼤ ⼈ な ん で す ■ 先 ほ ど ま で の 楽 し そ う な 空 気 に 戻 て つ き ま し た よ ● ⾨ を 開 け る ⾳ ★ 右 斜 め 前 ▲ 通 常 ■ 坦 々 と 説 明 こ こ ︑ 祖 ⽗ の 家 な ん で す け ど 偶 然 ︑ ⼤ 学 に 近 く て 在 学 中 は 私 が ⼆ 階 に 住 ま わ せ て も ら て い た ん で す で も ⼆ 年 前 に 亡 く な て 今 は 私 ⼀ ⼈ で 暮 ら し て い ま す ● 家 の 扉 を 開 け る ⾳ ■ 申 し 訳 な さ そ う に 少 し 物 が 多 い で す け ど ︑ ど う ぞ ● ⾜ ⾳ ︵ 家 の 中 ︶ ■ 苦 笑 い し な が ら 壁 ︑ す ご い で す よ ね 絵 画 を 集 め る の が 祖 ⽗ の 趣 味 だ た ん で す け ど 家 中 の 壁 ⼀ ⾯ に 飾 る の は ち と 不 気 味 で す よ ね ● 主 ⼈ 公 が ﹁ お ⾦ 持 ち の お 祖 ⽗ さ ん だ た ん だ ね ﹂ と 返 答 ■ 思 案 し て う ん … お ⾦ 持 ち ︑ か は … ど う で し う か ■ ⾒ 下 し た よ う な 笑 み ︒ 闇 を 感 じ さ せ る 感 じ で こ れ 全 部 レ プ リ カ な ん で す よ ■ 興 味 な さ そ う に 本 ⼈ は 絵 を 飾 る の が 趣 味 で 本 物 か ど う か は ど う で も よ か た ん で す 偽 物 で も ︑ ⼿ の 届 く と こ ろ に あ れ ば 満 ⾜ で き る そ ん な 感 じ な ん で す か ね ● 部 屋 の 扉 を 開 け る ★ 右 斜 め 前 ▲ 通 常 ■ ⾃ 信 満 々 で 嬉 し そ う に ︒ テ ン シ ン ⾼ め で じ ん こ こ が 私 の ア ト リ エ で す ど う で す か イ ン テ リ ア ︑ 結 構 こ だ わ て る ん で す よ 絵 を 描 い て い る と ⽬ が 疲 れ る の で 植 ⽊ 鉢 に 緑 を 沢 ⼭ 置 い て る ん で す ■ 苦 笑 い し て あ ︑ そ れ 全 部 造 花 で す よ ■ ⾸ を 傾 げ て 思 案 す る が ︑ す ぐ に 興 味 を 無 く す 感 じ で い や … 花 は な い か ら 造 草 … ？\n","Translated Text:<|im_end|>\n","<|im_start|>assistant\n","\n","\u001b[32m2024-10-14 02:58:59\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Incoming request api: http://b1b7-34-32-252-14.ngrok-free.app/v1/chat/completions\n","\u001b[32m2024-10-14 02:58:59\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Incoming request api: http://b1b7-34-32-252-14.ngrok-free.app/v1/chat/completions\n","\u001b[32m2024-10-14 02:58:59\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Incoming request api: http://b1b7-34-32-252-14.ngrok-free.app/v1/chat/completions\n","\u001b[32m2024-10-14 02:58:59\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m client: Address(host='127.0.0.1', port=46766)\n","\u001b[32m2024-10-14 02:58:59\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m client: Address(host='127.0.0.1', port=46780)\n","\u001b[32m2024-10-14 02:58:59\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m client: Address(host='127.0.0.1', port=46794)\n","\u001b[32m2024-10-14 02:58:59\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Incoming request api: http://b1b7-34-32-252-14.ngrok-free.app/v1/chat/completions\n","\u001b[32m2024-10-14 02:58:59\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m translate: <|im_start|>system\n","You are a highly skilled translation engine with expertise in eBook translation. Your function is to translate eBook texts accurately into the Simplified Chinese Language, maintaining the original tone, style, and formatting. Focus on delivering translations that resonate with the intended audience while ensuring the essence of the original text is preserved.<|im_end|>\n","<|im_start|>user\n","Translate the following source text to Simplified Chinese Language, Output translation directly without any additional text.\n","Source Text: ■ 少 し む と し て も う … ■ 不 服 そ う に 酷 い で す よ ︑ 先 ⽣ 恩 師 に 忘 れ ら れ て い た な ん て ︑ 傷 つ い ち い ま す ■ 納 得 し て 理 解 を ⽰ す が ︑ 少 し 寂 し そ う に ま ︑ で も … 先 ⽣ は 毎 年 沢 ⼭ の 新 ⼊ ⽣ の 顔 を 覚 え な き い け な い で し う し 卒 業 し た ⽣ 徒 の こ と ︑ 覚 え て い る ⽅ が 難 し い で す よ ね ■ ⾃ 分 の 髪 を 弄 り な が ら ︑ 独 り ⾔ を 呟 く よ う に ⾒ た ⽬ も … 髪 が 結 構 伸 び ま し た し 癖 ⽑ だ て ︑ 今 は 矯 正 し て ま す ■ 少 し 寂 し そ う に 先 ⽣ の 中 の 私 の 印 象 は あ の 頃 の ま ま で す よ ね ● 主 ⼈ 公 が ﹁ 雁 夜 さ ん は 雰 囲 気 が 変 わ た ﹂ と 返 答 ■ ⾸ を 傾 げ な が ら 雰 囲 気 … で す か ？ ● 主 ⼈ 公 が ﹁ 別 ⼈ み た い に ⼤ ⼈ び て た ﹂ と 返 答 ■ 苦 笑 し な が ら 別 ⼈ て … そ れ ︑ 褒 め て る ん で す か ？\n","Translated Text:<|im_end|>\n","<|im_start|>assistant\n","\n","\u001b[32m2024-10-14 02:58:59\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m translate: <|im_start|>system\n","You are a highly skilled translation engine with expertise in eBook translation. Your function is to translate eBook texts accurately into the Simplified Chinese Language, maintaining the original tone, style, and formatting. Focus on delivering translations that resonate with the intended audience while ensuring the essence of the original text is preserved.<|im_end|>\n","<|im_start|>user\n","Translate the following source text to Simplified Chinese Language, Output translation directly without any additional text.\n","Source Text:  ■ 相 ⼿ を 労 わ る よ う に 汗 も か い て ま す し … 余 程 ⼤ 変 な 夢 を ⾒ ら れ た ん で す ね … ■ 落 ち 着 か せ る よ う に ⼤ 丈 夫 で す よ … ⼤ 丈 夫 … さ ︑ こ ち ら に ど う ぞ 晩 ご 飯 の ご ⽤ 意 ︑ 出 来 て い ま す か ら\n","Translated Text:<|im_end|>\n","<|im_start|>assistant\n","\n","\u001b[32m2024-10-14 02:58:59\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m client: Address(host='127.0.0.1', port=46808)\n","\u001b[32m2024-10-14 02:58:59\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m translate: <|im_start|>system\n","You are a highly skilled translation engine with expertise in eBook translation. Your function is to translate eBook texts accurately into the Simplified Chinese Language, maintaining the original tone, style, and formatting. Focus on delivering translations that resonate with the intended audience while ensuring the essence of the original text is preserved.<|im_end|>\n","<|im_start|>user\n","Translate the following source text to Simplified Chinese Language, Output translation directly without any additional text.\n","Source Text: そ ろ そ ろ 課 題 を ⼀ 枚 仕 上 げ な い と い け な い ん で す け ど 構 図 で 悩 ん で い て … ■ 嬉 し そ う に は い … ま た 後 ⽇ で い い の で 是 ⾮ あ ︑ 先 ⽣ も 遠 慮 せ ず に ど ん ど ん 飲 ん で く だ さ い お 注 ぎ し ま す ね … ● ⽸ ビ ル を 開 け て グ ラ ス に 注 ぐ ⾳ ■ し み じ み と で も … も う 五 年 も 経 ち た ん で す ね 時 間 の 流 れ て 早 い で す ● そ ろ そ ろ 帰 ろ う ⽴ ち 上 が る 主 ⼈ 公 ★ 正 ⾯ 下 ▲ 通 常 ■ 少 し 悲 し そ う に あ れ … も う ︑ 帰 ら れ る ん で す か ？ ま だ ⼗ ⼋ 時 で す よ ？ 晩 ご 飯 ご 馳 ⾛ し よ う と 思 て い た の で す が … ■ し ん と し て あ ︑ そ う で す よ ね … 今 は ご 家 庭 が あ り ま す も ん ね ご め ん な さ い … 奥 さ ん が 待 て ま す も ん ね ■ 嘆 息 …… ︒ ● 主 ⼈ 公 が ﹁ 実 は 最 近 … 家 で は ⾷ べ て な い ん だ け ど ね ﹂ と 返 答 ■ 意 外 そ う に え … ？ ご 飯 お 家 で ⾷ べ な い ん で す か ？ ■ 不 思 議 そ う に え と … 何 か … 喧 嘩 で も さ れ た の で す か ？ ● 主 ⼈ 公 が ﹁ ま ︑ ⾊ 々 と ね … ﹂ と 濁 す 返 答 ■ ま だ 少 し 納 得 で き て い な い 様 ⼦ で そ う ︑ で す か … お し ど り 夫 婦 と 聞 い て い た の で … ■ 気 ま ず そ う に …… ︒ ■ 気 遣 う よ う に ま ︑ 夫 婦 仲 に も ⾊ 々 あ り ま す よ ね ■ ⾊ 々 な 悲 し い 変 化 を 割 り 切 ろ う と ︑ ⾃ ら を 納 得 さ せ る よ う に 無 理 に 明 る く 先 ⽣ が ご 結 婚 さ れ た の も 五 年 前 で し た し 美 術 の 授 業 も そ う で す け ど ︑ 五 年 も あ れ ば 何 も か も が 変 わ て し ま う な ん て … よ く あ る こ と な の か も し れ ま せ ん ね ● 千 織 も 椅 ⼦ か ら ⽴ ち 上 が る ★ 正 ⾯ ▲ 通 常 ■ 励 ま す よ う に 明 る く じ あ 先 ⽣ ︑ 尚 更 お 料 理 ⾷ べ て い て く だ さ い ■ や さ し く 明 る く 最 近 外 ⾷ ば か り な ん で す よ ね ？\n","Translated Text:<|im_end|>\n","<|im_start|>assistant\n","\n","\u001b[32m2024-10-14 02:58:59\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m translate: <|im_start|>system\n","You are a highly skilled translation engine with expertise in eBook translation. Your function is to translate eBook texts accurately into the Simplified Chinese Language, maintaining the original tone, style, and formatting. Focus on delivering translations that resonate with the intended audience while ensuring the essence of the original text is preserved.<|im_end|>\n","<|im_start|>user\n","Translate the following source text to Simplified Chinese Language, Output translation directly without any additional text.\n","Source Text: そ れ で は 栄 養 が 偏 て ダ メ で す よ な の で 今 夜 は 私 が 温 か い ⼿ 料 理 で 先 ⽣ を 労 ち い ま す 出 来 上 が る ま で 少 し お 時 間 い た だ き ま す の で よ か た ら 奥 の ベ ド で 休 ん で い て く だ さ い ■ 苦 笑 い し な が ら 先 ⽣ ︑ フ ラ フ ラ で す よ ？ 結 構 飲 み ま し た か ら ね 仕 ⽅ あ り ま せ ん ■ ⾃ 信 満 々 に ︑ 少 し ド ヤ て 私 で す か ？ こ の と お り ︑ ⼤ 丈 夫 で す ■ 静 か に 微 笑 し な が ら 私 … 酔 え な い ん で す ■ 苦 笑 い し な が ら ほ ら … ⾸ か く か く し て ま す よ ？ ★ 左 下 ▲ 近 距 離 ■ 肩 を 貸 し て ︑ や さ し く 介 抱 … ︑ さ … 先 ⽣ は ベ ド で ︑ ⼤ ⼈ し く 休 ん で い て く だ さ い ● 肩 を 貸 し て 主 ⼈ 公 を 介 抱 し 寝 室 の ベ ド に 向 か う ○ 介 抱 し て 肩 を 貸 し な が ら の 移 動 す る 時 の 息 遣 い ︵ ア ド リ ブ ５ 秒 程 度 ︶ ● ⾜ ⾳ ● 扉 を 開 け る ● ベ ド に 倒 れ る ⾳ ★ 正 ⾯ 上 ▲ 近 距 離 ■ 嬉 し そ う に 晩 ご 飯 の ⽀ 度 が 出 来 ま し た ら ︑ 呼 び に き ま す ね ■ 静 か に う と り し て そ れ で は … お や す み な さ い 先 ︑ ⽣ … ● 暗 転 ● 夢 を ⾒ て い る よ う な 印 象 に な る よ う に 軽 く エ コ あ り ● 千 織 が 騎 乗 位 で 主 ⼈ 公 を 逆 レ イ プ し て い る ★ 正 ⾯ ▲ 近 距 離 ■ 嬉 し そ う に 喘 ぐ ん … ︑ は … は … ︑ は あ ︑ あ … あ ︑ あ ん … は う ︑ う … は ん ︑ ん … ん ふ … あ う ︑ う う ん ■ 恍 惚 と し た 様 ⼦ で せ ん ︑ せ … 気 持 ち ︑ い い … で す か ？ 私 も … 気 持 ち ︑ い い … で す よ … せ ん せ … ● ⽬ を 覚 ま す ★ 右 斜 め 前 上 ▲ 通 常 ■ き と ん と し た 様 ⼦ で 先 ⽣ … ？ せ ん ︑ せ ？ ど う し た ん で す か ？ 横 に な ら れ る 前 よ り も ︑ お 顔 が 真 ⾚ じ な い で す か ■ か ら か う よ う に 微 笑 ん で も し か し て … 変 な 夢 で も ⾒ ま し た ？\n","Translated Text:<|im_end|>\n","<|im_start|>assistant\n","\n","\n","llama_print_timings:        load time =    1268.44 ms\n","llama_print_timings:      sample time =     104.98 ms /   512 runs   (    0.21 ms per token,  4876.98 tokens per second)\n","llama_print_timings: prompt eval time =    2067.29 ms /   941 tokens (    2.20 ms per token,   455.19 tokens per second)\n","llama_print_timings:        eval time =   33140.46 ms /   511 runs   (   64.85 ms per token,    15.42 tokens per second)\n","llama_print_timings:       total time =   36456.12 ms /  1452 tokens\n","{'choices': [{'finish_reason': 'length',\n","              'index': 0,\n","              'logprobs': None,\n","              'text': '● 蝉 声 ︒ 下 坡 道 公 鸡 ★ 左 前 方 ▲ 中 等 距 离 ■ 惊 喜 咚 嗞 先 ︑ 生 … ？ '\n","                      '● 接 近 而 来 公 鸡 ★ 左 前 方 ▲ 通 常 ■ 稍 微 兴 奋 气 恋 恋 好 像 很 开 心 久 '\n","                      '未 联 系 ︒ 先 生 ★ 左 前 方 ▲ 通 常 ↓ ︵ 移 动 ︶ ★ 正 面 ▲ 通 常 ■ 微 笑 着 '\n","                      '怎 么 了 ？ 那 张 脸 难 道 … 忘 记 我 了 ？ ■ 恋 恋 好 像 很 开 心 的 雁 夜 ︒ 雁 '\n","                      '夜 千 織 高 校 以 来 … 五 年 不 见 了 吧 ？ 记 得 吗 是 美 术 部 教 过 你 画 画 的 '\n","                      '人 ■ 能 让 你 回 忆 起 来 我 感 到 很 满 足 嗯 ︑ 嗯 … ■ 看 来 是 因 为 放 心 才 '\n","                      '回 忆 起 来 的 吗 我 ︑ 就 住 在 这 里 附近 大 学 很 近 所 以 来 探 望 样 子 你 的 '\n","                      '… 你 是 来 看 我 们 大 学 的 展 览 会 ？ ■ 尊 敬 的 眼 神 果 然 … 流 莉 是 美 术 '\n","                      '教 师 呢 ■ 好 像 很 开 心 地 期 待 着 明 年 我 也 会 参 加 展'}],\n"," 'created': 1728874739,\n"," 'id': 'cmpl-818fcbc2-5539-4b79-aae2-e3da95d2b3ae',\n"," 'model': './models/sakura-14b-qwen2.5-v1.0-iq4xs.gguf',\n"," 'object': 'text_completion',\n"," 'usage': {'completion_tokens': 512,\n","           'prompt_tokens': 1030,\n","           'total_tokens': 1542}}\n","\u001b[32m2024-10-14 02:59:35\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mutils.model[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Output generated in 36.46 seconds (14.04 tokens/s, 512 tokens, context 1030 tokens)\n","\u001b[32m2024-10-14 02:59:35\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m answer: prompt_token=1030 new_token=512 text='● 蝉 声 ︒ 下 坡 道 公 鸡 ★ 左 前 方 ▲ 中 等 距 离 ■ 惊 喜 咚 嗞 先 ︑ 生 … ？ ● 接 近 而 来 公 鸡 ★ 左 前 方 ▲ 通 常 ■ 稍 微 兴 奋 气 恋 恋 好 像 很 开 心 久 未 联 系 ︒ 先 生 ★ 左 前 方 ▲ 通 常 ↓ ︵ 移 动 ︶ ★ 正 面 ▲ 通 常 ■ 微 笑 着 怎 么 了 ？ 那 张 脸 难 道 … 忘 记 我 了 ？ ■ 恋 恋 好 像 很 开 心 的 雁 夜 ︒ 雁 夜 千 織 高 校 以 来 … 五 年 不 见 了 吧 ？ 记 得 吗 是 美 术 部 教 过 你 画 画 的 人 ■ 能 让 你 回 忆 起 来 我 感 到 很 满 足 嗯 ︑ 嗯 … ■ 看 来 是 因 为 放 心 才 回 忆 起 来 的 吗 我 ︑ 就 住 在 这 里 附近 大 学 很 近 所 以 来 探 望 样 子 你 的 … 你 是 来 看 我 们 大 学 的 展 览 会 ？ ■ 尊 敬 的 眼 神 果 然 … 流 莉 是 美 术 教 师 呢 ■ 好 像 很 开 心 地 期 待 着 明 年 我 也 会 参 加 展' finish_reason='length'\n","Llama.generate: 89 prefix-match hit, remaining 1139 prompt tokens to eval\n","\n","llama_print_timings:        load time =    1268.44 ms\n","llama_print_timings:      sample time =      72.72 ms /   356 runs   (    0.20 ms per token,  4895.29 tokens per second)\n","llama_print_timings: prompt eval time =    2207.14 ms /  1139 tokens (    1.94 ms per token,   516.05 tokens per second)\n","llama_print_timings:        eval time =   24694.71 ms /   355 runs   (   69.56 ms per token,    14.38 tokens per second)\n","llama_print_timings:       total time =   27578.64 ms /  1494 tokens\n","{'choices': [{'finish_reason': 'stop',\n","              'index': 0,\n","              'logprobs': None,\n","              'text': '■ 看到我担心的样子，学长也叹了一口气，毕竟身体也不太好……● 主人公的回应想象 ﹁ 记得很清楚呢……︒ '\n","                      '确实今天也很热︑ 这样也不错呢﹂■ 相槌是……■ 温柔邀请的想象从这里走过去很快就到了也有冷茶哦■ '\n","                      '稍微有些不耐烦的样子而且……我︑ 还想让学长再看看我的画■ 好像很开心的样子啊……谢谢您那么……︑ '\n","                      '我来给您带路吧● 笑颜★ 左▲ 通常■ 微笑着今天也很热呢毕竟是夏天也没办法■ '\n","                      '好像很开心的样子啊……美术部怎么样了？■ 稍微有些得意地想让对话热烈起来混杂着闲谈在我身后︑ '\n","                      '有没有优秀且才华横溢的学弟呢？呵呵……虽说是一年浪人但还是艺大合格了？稍微有些自满吧■ '\n","                      '吃惊的样子诶……美术部没有了吗？是……这样啊■ 惊讶的样子诶……美术课也没有了吗？学长……︑■ '\n","                      '喃喃自语着转任……怎么会……■ 意气消沉……︒■ 安慰自己似的原本就是选修制的嘛■ '\n","                      '孤独的样子……是吗……现在是这种感觉啊美术课也没有了……︑ 真是变化无常呢■ 苦笑着啊哈哈︑ 感觉有些怀念呢■ '\n","                      '想要改变话题有些不自然地说起我来︑ 真的不知道我是谁吗？\\n'}],\n"," 'created': 1728874775,\n"," 'id': 'cmpl-27add49f-f617-4d29-a6c9-ce0412947fcd',\n"," 'model': './models/sakura-14b-qwen2.5-v1.0-iq4xs.gguf',\n"," 'object': 'text_completion',\n"," 'usage': {'completion_tokens': 355,\n","           'prompt_tokens': 1228,\n","           'total_tokens': 1583}}\n","\u001b[32m2024-10-14 03:00:03\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mutils.model[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Output generated in 27.59 seconds (12.87 tokens/s, 355 tokens, context 1228 tokens)\n","\u001b[32m2024-10-14 03:00:03\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m answer: prompt_token=1228 new_token=355 text='■ 看到我担心的样子，学长也叹了一口气，毕竟身体也不太好……● 主人公的回应想象 ﹁ 记得很清楚呢……︒ 确实今天也很热︑ 这样也不错呢﹂■ 相槌是……■ 温柔邀请的想象从这里走过去很快就到了也有冷茶哦■ 稍微有些不耐烦的样子而且……我︑ 还想让学长再看看我的画■ 好像很开心的样子啊……谢谢您那么……︑ 我来给您带路吧● 笑颜★ 左▲ 通常■ 微笑着今天也很热呢毕竟是夏天也没办法■ 好像很开心的样子啊……美术部怎么样了？■ 稍微有些得意地想让对话热烈起来混杂着闲谈在我身后︑ 有没有优秀且才华横溢的学弟呢？呵呵……虽说是一年浪人但还是艺大合格了？稍微有些自满吧■ 吃惊的样子诶……美术部没有了吗？是……这样啊■ 惊讶的样子诶……美术课也没有了吗？学长……︑■ 喃喃自语着转任……怎么会……■ 意气消沉……︒■ 安慰自己似的原本就是选修制的嘛■ 孤独的样子……是吗……现在是这种感觉啊美术课也没有了……︑ 真是变化无常呢■ 苦笑着啊哈哈︑ 感觉有些怀念呢■ 想要改变话题有些不自然地说起我来︑ 真的不知道我是谁吗？\\n' finish_reason='stop'\n","Llama.generate: 89 prefix-match hit, remaining 1016 prompt tokens to eval\n","\u001b[32m2024-10-14 03:00:41\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Incoming request api: http://b1b7-34-32-252-14.ngrok-free.app/v1/chat/completions\n","\u001b[32m2024-10-14 03:00:41\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m client: Address(host='127.0.0.1', port=60362)\n","\u001b[32m2024-10-14 03:00:41\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Incoming request api: http://b1b7-34-32-252-14.ngrok-free.app/v1/chat/completions\n","\u001b[32m2024-10-14 03:00:41\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m client: Address(host='127.0.0.1', port=60352)\n","\u001b[32m2024-10-14 03:00:41\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m translate: <|im_start|>system\n","You are a highly skilled translation engine with expertise in eBook translation. Your function is to translate eBook texts accurately into the Simplified Chinese Language, maintaining the original tone, style, and formatting. Focus on delivering translations that resonate with the intended audience while ensuring the essence of the original text is preserved.<|im_end|>\n","<|im_start|>user\n","Translate the following source text to Simplified Chinese Language, Output translation directly without any additional text.\n","Source Text:  ■ 相 ⼿ を 労 わ る よ う に 汗 も か い て ま す し … 余 程 ⼤ 変 な 夢 を ⾒ ら れ た ん で す ね … ■ 落 ち 着 か せ る よ う に ⼤ 丈 夫 で す よ … ⼤ 丈 夫 … さ ︑ こ ち ら に ど う ぞ 晩 ご 飯 の ご ⽤ 意 ︑ 出 来 て い ま す か ら\n","Translated Text:<|im_end|>\n","<|im_start|>assistant\n","\n","\u001b[32m2024-10-14 03:00:41\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m translate: <|im_start|>system\n","You are a highly skilled translation engine with expertise in eBook translation. Your function is to translate eBook texts accurately into the Simplified Chinese Language, maintaining the original tone, style, and formatting. Focus on delivering translations that resonate with the intended audience while ensuring the essence of the original text is preserved.<|im_end|>\n","<|im_start|>user\n","Translate the following source text to Simplified Chinese Language, Output translation directly without any additional text.\n","Source Text: そ れ で は 栄 養 が 偏 て ダ メ で す よ な の で 今 夜 は 私 が 温 か い ⼿ 料 理 で 先 ⽣ を 労 ち い ま す 出 来 上 が る ま で 少 し お 時 間 い た だ き ま す の で よ か た ら 奥 の ベ ド で 休 ん で い て く だ さ い ■ 苦 笑 い し な が ら 先 ⽣ ︑ フ ラ フ ラ で す よ ？ 結 構 飲 み ま し た か ら ね 仕 ⽅ あ り ま せ ん ■ ⾃ 信 満 々 に ︑ 少 し ド ヤ て 私 で す か ？ こ の と お り ︑ ⼤ 丈 夫 で す ■ 静 か に 微 笑 し な が ら 私 … 酔 え な い ん で す ■ 苦 笑 い し な が ら ほ ら … ⾸ か く か く し て ま す よ ？ ★ 左 下 ▲ 近 距 離 ■ 肩 を 貸 し て ︑ や さ し く 介 抱 … ︑ さ … 先 ⽣ は ベ ド で ︑ ⼤ ⼈ し く 休 ん で い て く だ さ い ● 肩 を 貸 し て 主 ⼈ 公 を 介 抱 し 寝 室 の ベ ド に 向 か う ○ 介 抱 し て 肩 を 貸 し な が ら の 移 動 す る 時 の 息 遣 い ︵ ア ド リ ブ ５ 秒 程 度 ︶ ● ⾜ ⾳ ● 扉 を 開 け る ● ベ ド に 倒 れ る ⾳ ★ 正 ⾯ 上 ▲ 近 距 離 ■ 嬉 し そ う に 晩 ご 飯 の ⽀ 度 が 出 来 ま し た ら ︑ 呼 び に き ま す ね ■ 静 か に う と り し て そ れ で は … お や す み な さ い 先 ︑ ⽣ … ● 暗 転 ● 夢 を ⾒ て い る よ う な 印 象 に な る よ う に 軽 く エ コ あ り ● 千 織 が 騎 乗 位 で 主 ⼈ 公 を 逆 レ イ プ し て い る ★ 正 ⾯ ▲ 近 距 離 ■ 嬉 し そ う に 喘 ぐ ん … ︑ は … は … ︑ は あ ︑ あ … あ ︑ あ ん … は う ︑ う … は ん ︑ ん … ん ふ … あ う ︑ う う ん ■ 恍 惚 と し た 様 ⼦ で せ ん ︑ せ … 気 持 ち ︑ い い … で す か ？ 私 も … 気 持 ち ︑ い い … で す よ … せ ん せ … ● ⽬ を 覚 ま す ★ 右 斜 め 前 上 ▲ 通 常 ■ き と ん と し た 様 ⼦ で 先 ⽣ … ？ せ ん ︑ せ ？ ど う し た ん で す か ？ 横 に な ら れ る 前 よ り も ︑ お 顔 が 真 ⾚ じ な い で す か ■ か ら か う よ う に 微 笑 ん で も し か し て … 変 な 夢 で も ⾒ ま し た ？\n","Translated Text:<|im_end|>\n","<|im_start|>assistant\n","\n","\u001b[32m2024-10-14 03:00:41\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Incoming request api: http://b1b7-34-32-252-14.ngrok-free.app/v1/chat/completions\n","\u001b[32m2024-10-14 03:00:41\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m client: Address(host='127.0.0.1', port=60386)\n","\u001b[32m2024-10-14 03:00:41\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Incoming request api: http://b1b7-34-32-252-14.ngrok-free.app/v1/chat/completions\n","\u001b[32m2024-10-14 03:00:41\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m client: Address(host='127.0.0.1', port=60366)\n","\u001b[32m2024-10-14 03:00:41\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m translate: <|im_start|>system\n","You are a highly skilled translation engine with expertise in eBook translation. Your function is to translate eBook texts accurately into the Simplified Chinese Language, maintaining the original tone, style, and formatting. Focus on delivering translations that resonate with the intended audience while ensuring the essence of the original text is preserved.<|im_end|>\n","<|im_start|>user\n","Translate the following source text to Simplified Chinese Language, Output translation directly without any additional text.\n","Source Text: そ ろ そ ろ 課 題 を ⼀ 枚 仕 上 げ な い と い け な い ん で す け ど 構 図 で 悩 ん で い て … ■ 嬉 し そ う に は い … ま た 後 ⽇ で い い の で 是 ⾮ あ ︑ 先 ⽣ も 遠 慮 せ ず に ど ん ど ん 飲 ん で く だ さ い お 注 ぎ し ま す ね … ● ⽸ ビ ル を 開 け て グ ラ ス に 注 ぐ ⾳ ■ し み じ み と で も … も う 五 年 も 経 ち た ん で す ね 時 間 の 流 れ て 早 い で す ● そ ろ そ ろ 帰 ろ う ⽴ ち 上 が る 主 ⼈ 公 ★ 正 ⾯ 下 ▲ 通 常 ■ 少 し 悲 し そ う に あ れ … も う ︑ 帰 ら れ る ん で す か ？ ま だ ⼗ ⼋ 時 で す よ ？ 晩 ご 飯 ご 馳 ⾛ し よ う と 思 て い た の で す が … ■ し ん と し て あ ︑ そ う で す よ ね … 今 は ご 家 庭 が あ り ま す も ん ね ご め ん な さ い … 奥 さ ん が 待 て ま す も ん ね ■ 嘆 息 …… ︒ ● 主 ⼈ 公 が ﹁ 実 は 最 近 … 家 で は ⾷ べ て な い ん だ け ど ね ﹂ と 返 答 ■ 意 外 そ う に え … ？ ご 飯 お 家 で ⾷ べ な い ん で す か ？ ■ 不 思 議 そ う に え と … 何 か … 喧 嘩 で も さ れ た の で す か ？ ● 主 ⼈ 公 が ﹁ ま ︑ ⾊ 々 と ね … ﹂ と 濁 す 返 答 ■ ま だ 少 し 納 得 で き て い な い 様 ⼦ で そ う ︑ で す か … お し ど り 夫 婦 と 聞 い て い た の で … ■ 気 ま ず そ う に …… ︒ ■ 気 遣 う よ う に ま ︑ 夫 婦 仲 に も ⾊ 々 あ り ま す よ ね ■ ⾊ 々 な 悲 し い 変 化 を 割 り 切 ろ う と ︑ ⾃ ら を 納 得 さ せ る よ う に 無 理 に 明 る く 先 ⽣ が ご 結 婚 さ れ た の も 五 年 前 で し た し 美 術 の 授 業 も そ う で す け ど ︑ 五 年 も あ れ ば 何 も か も が 変 わ て し ま う な ん て … よ く あ る こ と な の か も し れ ま せ ん ね ● 千 織 も 椅 ⼦ か ら ⽴ ち 上 が る ★ 正 ⾯ ▲ 通 常 ■ 励 ま す よ う に 明 る く じ あ 先 ⽣ ︑ 尚 更 お 料 理 ⾷ べ て い て く だ さ い ■ や さ し く 明 る く 最 近 外 ⾷ ば か り な ん で す よ ね ？\n","Translated Text:<|im_end|>\n","<|im_start|>assistant\n","\n","\u001b[32m2024-10-14 03:00:41\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Incoming request api: http://b1b7-34-32-252-14.ngrok-free.app/v1/chat/completions\n","\u001b[32m2024-10-14 03:00:41\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m translate: <|im_start|>system\n","You are a highly skilled translation engine with expertise in eBook translation. Your function is to translate eBook texts accurately into the Simplified Chinese Language, maintaining the original tone, style, and formatting. Focus on delivering translations that resonate with the intended audience while ensuring the essence of the original text is preserved.<|im_end|>\n","<|im_start|>user\n","Translate the following source text to Simplified Chinese Language, Output translation directly without any additional text.\n","Source Text: ま ︑ 呼 び ⽅ は ど う で も い い で す ね ■ 楽 し そ う に 普 段 は こ こ に 座 て こ の イ ゼ ル に キ ン バ ス を ⽴ て て 描 い て い ま す 素 敵 で す よ ね ？ ■ 嬉 し そ う に う ふ ふ ︑ よ か た … 気 に い て も ら え て ■ ハ と し た 様 ⼦ で あ … 飲 み 物 忘 れ て ま し た ■ 申 し 訳 な さ そ う に ご め ん な さ い … ⼈ が 来 る こ と が 滅 多 に な い も の で す か ら ■ そ わ そ わ し た 様 ⼦ で 嬉 し そ う に 期 待 し て そ う だ … ︑ 私 も う 成 ⼈ し て る の で お 酒 飲 め る よ う に な た ん で す よ ■ い じ ら し い 様 ⼦ で 少 し 早 い 時 間 で す け ど ⼀ 緒 に ど う で す か ？ ■ し み じ み と 胸 の 内 を 吐 露 す る 私 … 昔 の 思 い 出 話 を し な が ら ⼀ 杯 や る の が 夢 だ た ん で す ■ い じ ら し い 様 ⼦ で 付 き 合 て … く れ ま せ ん か ？ ■ 嬉 し そ う に あ り が と う ご ざ い ま す … ● 時 間 経 過 ★ 正 ⾯ ▲ 通 常 ■ 楽 し そ う に そ れ で 美 術 室 の 鍵 … 結 局 先 ⽣ の ポ ケ ト に ⼊ て た ん で す よ ね ■ 頬 を 膨 ら ま せ る 感 じ で ︑ 可 愛 く 怒 る ⼤ 変 だ た ん で す よ ？ 鍵 が 無 く て 施 錠 で き な い と 帰 れ な い の で ︑ 焦 り ま し た … ■ 嬉 し そ う に ま ︑ 今 と な て は い い 思 い 出 で す ■ お 酒 を 飲 む ご く … ご く ︑ ご く ︑ は … ■ し み じ み と 先 ⽣ に 絵 を ご 指 導 い た だ い た 三 年 間 … 本 当 に ⼤ 切 な ︑ か え が え の な い ⽇ 々 で し た ■ 少 し 申 し 訳 な さ そ う に そ う だ ︑ ま た 私 の 絵 を ⾒ て い た だ け な い で し う か ？\n","Translated Text:<|im_end|>\n","<|im_start|>assistant\n","\n","\u001b[32m2024-10-14 03:00:41\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Incoming request api: http://b1b7-34-32-252-14.ngrok-free.app/v1/chat/completions\n","\u001b[32m2024-10-14 03:00:41\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m client: Address(host='127.0.0.1', port=60390)\n","\u001b[32m2024-10-14 03:00:41\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m client: Address(host='127.0.0.1', port=60370)\n","\u001b[32m2024-10-14 03:00:41\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m translate: <|im_start|>system\n","You are a highly skilled translation engine with expertise in eBook translation. Your function is to translate eBook texts accurately into the Simplified Chinese Language, maintaining the original tone, style, and formatting. Focus on delivering translations that resonate with the intended audience while ensuring the essence of the original text is preserved.<|im_end|>\n","<|im_start|>user\n","Translate the following source text to Simplified Chinese Language, Output translation directly without any additional text.\n","Source Text: ● ⾜ を ⽌ め る ■ 嘆 息 ふ ん … ★ 正 ⾯ ▲ 通 常 ■ ⼝ 元 に ⼈ 差 し 指 を 当 て て ︑ 静 か に 諭 す よ う に ︒ こ こ の 台 詞 だ け ミ ス テ リ ア ス に 先 ⽣ ⼥ の ⼦ は 変 わ る ん で す よ も う ⼆ ⼗ 歳 な ん で す か ら ︑ ⼤ ⼈ な ん で す ■ 先 ほ ど ま で の 楽 し そ う な 空 気 に 戻 て つ き ま し た よ ● ⾨ を 開 け る ⾳ ★ 右 斜 め 前 ▲ 通 常 ■ 坦 々 と 説 明 こ こ ︑ 祖 ⽗ の 家 な ん で す け ど 偶 然 ︑ ⼤ 学 に 近 く て 在 学 中 は 私 が ⼆ 階 に 住 ま わ せ て も ら て い た ん で す で も ⼆ 年 前 に 亡 く な て 今 は 私 ⼀ ⼈ で 暮 ら し て い ま す ● 家 の 扉 を 開 け る ⾳ ■ 申 し 訳 な さ そ う に 少 し 物 が 多 い で す け ど ︑ ど う ぞ ● ⾜ ⾳ ︵ 家 の 中 ︶ ■ 苦 笑 い し な が ら 壁 ︑ す ご い で す よ ね 絵 画 を 集 め る の が 祖 ⽗ の 趣 味 だ た ん で す け ど 家 中 の 壁 ⼀ ⾯ に 飾 る の は ち と 不 気 味 で す よ ね ● 主 ⼈ 公 が ﹁ お ⾦ 持 ち の お 祖 ⽗ さ ん だ た ん だ ね ﹂ と 返 答 ■ 思 案 し て う ん … お ⾦ 持 ち ︑ か は … ど う で し う か ■ ⾒ 下 し た よ う な 笑 み ︒ 闇 を 感 じ さ せ る 感 じ で こ れ 全 部 レ プ リ カ な ん で す よ ■ 興 味 な さ そ う に 本 ⼈ は 絵 を 飾 る の が 趣 味 で 本 物 か ど う か は ど う で も よ か た ん で す 偽 物 で も ︑ ⼿ の 届 く と こ ろ に あ れ ば 満 ⾜ で き る そ ん な 感 じ な ん で す か ね ● 部 屋 の 扉 を 開 け る ★ 右 斜 め 前 ▲ 通 常 ■ ⾃ 信 満 々 で 嬉 し そ う に ︒ テ ン シ ン ⾼ め で じ ん こ こ が 私 の ア ト リ エ で す ど う で す か イ ン テ リ ア ︑ 結 構 こ だ わ て る ん で す よ 絵 を 描 い て い る と ⽬ が 疲 れ る の で 植 ⽊ 鉢 に 緑 を 沢 ⼭ 置 い て る ん で す ■ 苦 笑 い し て あ ︑ そ れ 全 部 造 花 で す よ ■ ⾸ を 傾 げ て 思 案 す る が ︑ す ぐ に 興 味 を 無 く す 感 じ で い や … 花 は な い か ら 造 草 … ？\n","Translated Text:<|im_end|>\n","<|im_start|>assistant\n","\n","\u001b[32m2024-10-14 03:00:41\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m translate: <|im_start|>system\n","You are a highly skilled translation engine with expertise in eBook translation. Your function is to translate eBook texts accurately into the Simplified Chinese Language, maintaining the original tone, style, and formatting. Focus on delivering translations that resonate with the intended audience while ensuring the essence of the original text is preserved.<|im_end|>\n","<|im_start|>user\n","Translate the following source text to Simplified Chinese Language, Output translation directly without any additional text.\n","Source Text: ■ 少 し む と し て も う … ■ 不 服 そ う に 酷 い で す よ ︑ 先 ⽣ 恩 師 に 忘 れ ら れ て い た な ん て ︑ 傷 つ い ち い ま す ■ 納 得 し て 理 解 を ⽰ す が ︑ 少 し 寂 し そ う に ま ︑ で も … 先 ⽣ は 毎 年 沢 ⼭ の 新 ⼊ ⽣ の 顔 を 覚 え な き い け な い で し う し 卒 業 し た ⽣ 徒 の こ と ︑ 覚 え て い る ⽅ が 難 し い で す よ ね ■ ⾃ 分 の 髪 を 弄 り な が ら ︑ 独 り ⾔ を 呟 く よ う に ⾒ た ⽬ も … 髪 が 結 構 伸 び ま し た し 癖 ⽑ だ て ︑ 今 は 矯 正 し て ま す ■ 少 し 寂 し そ う に 先 ⽣ の 中 の 私 の 印 象 は あ の 頃 の ま ま で す よ ね ● 主 ⼈ 公 が ﹁ 雁 夜 さ ん は 雰 囲 気 が 変 わ た ﹂ と 返 答 ■ ⾸ を 傾 げ な が ら 雰 囲 気 … で す か ？ ● 主 ⼈ 公 が ﹁ 別 ⼈ み た い に ⼤ ⼈ び て た ﹂ と 返 答 ■ 苦 笑 し な が ら 別 ⼈ て … そ れ ︑ 褒 め て る ん で す か ？\n","Translated Text:<|im_end|>\n","<|im_start|>assistant\n","\n","\n","llama_print_timings:        load time =    1268.44 ms\n","llama_print_timings:      sample time =     110.47 ms /   512 runs   (    0.22 ms per token,  4634.57 tokens per second)\n","llama_print_timings: prompt eval time =    1982.29 ms /  1016 tokens (    1.95 ms per token,   512.54 tokens per second)\n","llama_print_timings:        eval time =   36308.83 ms /   511 runs   (   71.05 ms per token,    14.07 tokens per second)\n","llama_print_timings:       total time =   39330.88 ms /  1527 tokens\n","{'choices': [{'finish_reason': 'length',\n","              'index': 0,\n","              'logprobs': None,\n","              'text': '真 ︑ 呼 ～ 呼 ～ 你 怎 么 会 在 这 里 呢 ？ 你 一 定 很 高 兴 吧 ？ 平 时 你 都 是 '\n","                      '坐 在 这 里 画 着 那 个 伊 耶 尔 金 巴 斯 吧 ？ 真 是 令 人 妒 忌 呢 ？ 你 一 定 很 '\n","                      '高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ '\n","                      '你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 '\n","                      '高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ '\n","                      '你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 '\n","                      '高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ '\n","                      '你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 '\n","                      '高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ '\n","                      '你'}],\n"," 'created': 1728874803,\n"," 'id': 'cmpl-847662af-3294-4273-847c-bddbdff80835',\n"," 'model': './models/sakura-14b-qwen2.5-v1.0-iq4xs.gguf',\n"," 'object': 'text_completion',\n"," 'usage': {'completion_tokens': 512,\n","           'prompt_tokens': 1105,\n","           'total_tokens': 1617}}\n","\u001b[32m2024-10-14 03:00:42\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mutils.model[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Output generated in 39.34 seconds (13.02 tokens/s, 512 tokens, context 1105 tokens)\n","\u001b[32m2024-10-14 03:00:42\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m answer: prompt_token=1105 new_token=512 text='真 ︑ 呼 ～ 呼 ～ 你 怎 么 会 在 这 里 呢 ？ 你 一 定 很 高 兴 吧 ？ 平 时 你 都 是 坐 在 这 里 画 着 那 个 伊 耶 尔 金 巴 斯 吧 ？ 真 是 令 人 妒 忌 呢 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你 一 定 很 高 兴 吧 ？ 你' finish_reason='length'\n","Llama.generate: 89 prefix-match hit, remaining 1269 prompt tokens to eval\n","\n","llama_print_timings:        load time =    1268.44 ms\n","llama_print_timings:      sample time =     146.27 ms /   309 runs   (    0.47 ms per token,  2112.60 tokens per second)\n","llama_print_timings: prompt eval time =    2488.75 ms /  1269 tokens (    1.96 ms per token,   509.90 tokens per second)\n","llama_print_timings:        eval time =   22475.32 ms /   308 runs   (   72.97 ms per token,    13.70 tokens per second)\n","llama_print_timings:       total time =   26604.51 ms /  1577 tokens\n","{'choices': [{'finish_reason': 'stop',\n","              'index': 0,\n","              'logprobs': None,\n","              'text': '●叹气■呼……★正脸▲通常■用食指抵住嘴边︑静静地劝告︒只有这句台词让神秘推理的先生成了另一个人，真是的，都已经二十岁了︑已经是大人了■恢复到刚才为止的愉快气氛●打开门★右斜前方▲通常■坦然地说明︑虽然是祖父的家，但因为离大学很近，所以在学期间我住在二楼，但祖父两年前去世了，现在只有我一个人住●打开家门■抱歉，东西有点多︑请进●叹气︵在家里面︶■苦笑着看着墙壁︑很厉害吧，祖父的兴趣是收集绘画，但把画挂在家中的一面墙上，有点可怕呢●主人公「﹁祖父是很有钱的人吧﹂」回答■思考……有钱吗……？■露出轻视的笑容︒让人感觉到黑暗，这些全部都是复制品■不感兴趣，本人的兴趣是装饰绘画，是不是真品都无所谓，就算是赝品︑只要放在手边就能满足，就是这种感觉吧●打开房间的门★右斜前方▲通常■自信满满，很开心︒心情很好，这里是我的工作室，怎么样，很时尚吧︑很讲究结构哦，画画的时候眼睛会疲劳，所以放了植物盆栽来增加绿意■苦笑︑那些全部都是人造花■歪着头思考︑但很快就失去了兴趣，哎……没有花，所以是人造草……？\\n'}],\n"," 'created': 1728874842,\n"," 'id': 'cmpl-45c3b5eb-4e4f-4c89-baed-265939407187',\n"," 'model': './models/sakura-14b-qwen2.5-v1.0-iq4xs.gguf',\n"," 'object': 'text_completion',\n"," 'usage': {'completion_tokens': 308,\n","           'prompt_tokens': 1358,\n","           'total_tokens': 1666}}\n","\u001b[32m2024-10-14 03:01:09\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mutils.model[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Output generated in 26.61 seconds (11.57 tokens/s, 308 tokens, context 1358 tokens)\n","\u001b[32m2024-10-14 03:01:09\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m answer: prompt_token=1358 new_token=308 text='●叹气■呼……★正脸▲通常■用食指抵住嘴边︑静静地劝告︒只有这句台词让神秘推理的先生成了另一个人，真是的，都已经二十岁了︑已经是大人了■恢复到刚才为止的愉快气氛●打开门★右斜前方▲通常■坦然地说明︑虽然是祖父的家，但因为离大学很近，所以在学期间我住在二楼，但祖父两年前去世了，现在只有我一个人住●打开家门■抱歉，东西有点多︑请进●叹气︵在家里面︶■苦笑着看着墙壁︑很厉害吧，祖父的兴趣是收集绘画，但把画挂在家中的一面墙上，有点可怕呢●主人公「﹁祖父是很有钱的人吧﹂」回答■思考……有钱吗……？■露出轻视的笑容︒让人感觉到黑暗，这些全部都是复制品■不感兴趣，本人的兴趣是装饰绘画，是不是真品都无所谓，就算是赝品︑只要放在手边就能满足，就是这种感觉吧●打开房间的门★右斜前方▲通常■自信满满，很开心︒心情很好，这里是我的工作室，怎么样，很时尚吧︑很讲究结构哦，画画的时候眼睛会疲劳，所以放了植物盆栽来增加绿意■苦笑︑那些全部都是人造花■歪着头思考︑但很快就失去了兴趣，哎……没有花，所以是人造草……？\\n' finish_reason='stop'\n","Llama.generate: 89 prefix-match hit, remaining 593 prompt tokens to eval\n","\n","llama_print_timings:        load time =    1268.44 ms\n","llama_print_timings:      sample time =     202.82 ms /   513 runs   (    0.40 ms per token,  2529.31 tokens per second)\n","llama_print_timings: prompt eval time =    1169.71 ms /   593 tokens (    1.97 ms per token,   506.96 tokens per second)\n","llama_print_timings:        eval time =   35352.12 ms /   512 runs   (   69.05 ms per token,    14.48 tokens per second)\n","llama_print_timings:       total time =   39362.77 ms /  1105 tokens\n","{'choices': [{'finish_reason': 'length',\n","              'index': 0,\n","              'logprobs': None,\n","              'text': '■ 稍 微 冷 静 一 点 吧 … ■ 不 服 气 似 的 太 残 忍 了 哦 ︑ 被 师 父 忘 记 了 ︑ '\n","                      '真 是 伤 心 ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ '\n","                      '︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ '\n","                      '︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ '\n","                      '︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ '\n","                      '︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ '\n","                      '︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑'}],\n"," 'created': 1728874869,\n"," 'id': 'cmpl-20efd9fd-1c37-4639-a8dd-b64897ae866f',\n"," 'model': './models/sakura-14b-qwen2.5-v1.0-iq4xs.gguf',\n"," 'object': 'text_completion',\n"," 'usage': {'completion_tokens': 513,\n","           'prompt_tokens': 682,\n","           'total_tokens': 1195}}\n","\u001b[32m2024-10-14 03:01:48\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mutils.model[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Output generated in 39.38 seconds (13.03 tokens/s, 513 tokens, context 682 tokens)\n","\u001b[32m2024-10-14 03:01:48\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m answer: prompt_token=682 new_token=513 text='■ 稍 微 冷 静 一 点 吧 … ■ 不 服 气 似 的 太 残 忍 了 哦 ︑ 被 师 父 忘 记 了 ︑ 真 是 伤 心 ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑' finish_reason='stop'\n","Llama.generate: 89 prefix-match hit, remaining 178 prompt tokens to eval\n","\n","llama_print_timings:        load time =    1268.44 ms\n","llama_print_timings:      sample time =      26.53 ms /    43 runs   (    0.62 ms per token,  1620.99 tokens per second)\n","llama_print_timings: prompt eval time =     371.60 ms /   178 tokens (    2.09 ms per token,   479.02 tokens per second)\n","llama_print_timings:        eval time =    2920.08 ms /    42 runs   (   69.53 ms per token,    14.38 tokens per second)\n","llama_print_timings:       total time =    3585.85 ms /   220 tokens\n","{'choices': [{'finish_reason': 'stop',\n","              'index': 0,\n","              'logprobs': None,\n","              'text': '■\\u3000你似乎很辛苦地流了汗……看来你做了个相当可怕的梦呢……■\\u3000'\n","                      '没事的，冷静下来……没事的……来，这边请。晚餐已经准备好了。」'}],\n"," 'created': 1728874908,\n"," 'id': 'cmpl-702c0422-c097-4769-9141-d22f128e3812',\n"," 'model': './models/sakura-14b-qwen2.5-v1.0-iq4xs.gguf',\n"," 'object': 'text_completion',\n"," 'usage': {'completion_tokens': 42, 'prompt_tokens': 267, 'total_tokens': 309}}\n","\u001b[32m2024-10-14 03:01:52\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mutils.model[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Output generated in 3.59 seconds (11.69 tokens/s, 42 tokens, context 267 tokens)\n","\u001b[32m2024-10-14 03:01:52\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m answer: prompt_token=267 new_token=42 text='■\\u3000你似乎很辛苦地流了汗……看来你做了个相当可怕的梦呢……■\\u3000没事的，冷静下来……没事的……来，这边请。晚餐已经准备好了。」' finish_reason='stop'\n","Llama.generate: 90 prefix-match hit, remaining 1215 prompt tokens to eval\n","\n","llama_print_timings:        load time =    1268.44 ms\n","llama_print_timings:      sample time =     177.96 ms /   512 runs   (    0.35 ms per token,  2877.07 tokens per second)\n","llama_print_timings: prompt eval time =    2599.21 ms /  1215 tokens (    2.14 ms per token,   467.45 tokens per second)\n","llama_print_timings:        eval time =   36913.40 ms /   511 runs   (   72.24 ms per token,    13.84 tokens per second)\n","llama_print_timings:       total time =   42079.63 ms /  1726 tokens\n","{'choices': [{'finish_reason': 'length',\n","              'index': 0,\n","              'logprobs': None,\n","              'text': '差 不 多 要 把 作 业 完 成 一 幅 了 但 是 在 烦 惭 构 图 …■ 好 像 很 开 心 … 请 '\n","                      '不 用 管 我 ︑ 先 生 也 不 用 管 我 请 继 续 喝 酒 我 来 给 您 倒 酒 …● 打 开 瓶 '\n","                      '子 倒 在 玻 璃 杯 里■ 声 音 响 起 来 … 已 经 过 了 五 年 了 时 间 过 得 真 快● 差 '\n","                      '不 多 要 回 去 了 主 人 公★ 正 面 下▲ 通 常■ 有 些 悲 伤 … 已 经︑ 要 回 去 了 吗 '\n","                      '？ 还 只 是 8 点 哦 ？ 我 还 想 说 要 去 您 家 吃 晚 饭 的 …■ 沉 默︑ 是 呢 … 现 '\n","                      '在 有 家 人 了 呢 对 不 起 … 妻 子 在 等 您 吧■ 叹 气……︒● 主 人 公﹁ 其 实 最 近 '\n","                      '… 在 家 里 没 有 吃 过 饭 哪 ﹂ 回 答■ 意 外 呢 …？ 在 家 里 没 有 吃 过 饭 吗 '\n","                      '？■ 不 可 思 议 呢 … 是 … 发 生 了 什 么 … 争 执 吗 ？● 主 人 公﹁ 具 ︑ 体 原 '\n","                      '因 说 不 出 来 … ﹂ 回 答■ 还 有 些 无 法 接 受 的 样 子︑ 是 呢 … 听 说 是 一 对 '\n","                      '恩 爱 的'}],\n"," 'created': 1728874912,\n"," 'id': 'cmpl-3df2fa76-c8bd-4fe7-a2ac-ac59c45a8fa7',\n"," 'model': './models/sakura-14b-qwen2.5-v1.0-iq4xs.gguf',\n"," 'object': 'text_completion',\n"," 'usage': {'completion_tokens': 512,\n","           'prompt_tokens': 1305,\n","           'total_tokens': 1817}}\n","\u001b[32m2024-10-14 03:02:34\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mutils.model[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Output generated in 42.12 seconds (12.16 tokens/s, 512 tokens, context 1305 tokens)\n","\u001b[32m2024-10-14 03:02:34\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m answer: prompt_token=1305 new_token=512 text='差 不 多 要 把 作 业 完 成 一 幅 了 但 是 在 烦 惭 构 图 …■ 好 像 很 开 心 … 请 不 用 管 我 ︑ 先 生 也 不 用 管 我 请 继 续 喝 酒 我 来 给 您 倒 酒 …● 打 开 瓶 子 倒 在 玻 璃 杯 里■ 声 音 响 起 来 … 已 经 过 了 五 年 了 时 间 过 得 真 快● 差 不 多 要 回 去 了 主 人 公★ 正 面 下▲ 通 常■ 有 些 悲 伤 … 已 经︑ 要 回 去 了 吗 ？ 还 只 是 8 点 哦 ？ 我 还 想 说 要 去 您 家 吃 晚 饭 的 …■ 沉 默︑ 是 呢 … 现 在 有 家 人 了 呢 对 不 起 … 妻 子 在 等 您 吧■ 叹 气……︒● 主 人 公﹁ 其 实 最 近 … 在 家 里 没 有 吃 过 饭 哪 ﹂ 回 答■ 意 外 呢 …？ 在 家 里 没 有 吃 过 饭 吗 ？■ 不 可 思 议 呢 … 是 … 发 生 了 什 么 … 争 执 吗 ？● 主 人 公﹁ 具 ︑ 体 原 因 说 不 出 来 … ﹂ 回 答■ 还 有 些 无 法 接 受 的 样 子︑ 是 呢 … 听 说 是 一 对 恩 爱 的' finish_reason='length'\n","Llama.generate: 92 prefix-match hit, remaining 1217 prompt tokens to eval\n","\u001b[32m2024-10-14 03:03:07\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Incoming request api: http://b1b7-34-32-252-14.ngrok-free.app/v1/chat/completions\n","\u001b[32m2024-10-14 03:03:07\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m client: Address(host='127.0.0.1', port=60794)\n","\u001b[32m2024-10-14 03:03:07\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m translate: <|im_start|>system\n","你是一个轻小说翻译模型，可以流畅通顺地以日本轻小说的风格将日文翻译成简体中文，并联系上下文正确使用人称代词，不擅自添加原文中没有的代词。<|im_end|>\n","<|im_start|>user\n","将下面的日文文本翻译成中文：国境の長いトンネルを抜けると雪国であった。夜の底が白くなった。信号所に汽車が止まった。<|im_end|>\n","<|im_start|>assistant\n","\n","\n","llama_print_timings:        load time =    1268.44 ms\n","llama_print_timings:      sample time =     132.45 ms /   512 runs   (    0.26 ms per token,  3865.52 tokens per second)\n","llama_print_timings: prompt eval time =    2439.68 ms /  1217 tokens (    2.00 ms per token,   498.84 tokens per second)\n","llama_print_timings:        eval time =   36557.10 ms /   511 runs   (   71.54 ms per token,    13.98 tokens per second)\n","llama_print_timings:       total time =   40241.35 ms /  1728 tokens\n","{'choices': [{'finish_reason': 'length',\n","              'index': 0,\n","              'logprobs': None,\n","              'text': '这 样 不 好 哦 会 导 致 营 养 不 均 今 天 晚 上 我 就 用 温 暖 的 手 做 出 来 劳 劳 '\n","                      '老 师 在 完 成 之 前 需 要 一 些 时 间 请 老 师 在 里 面 的 床 上 休 息 一 会 儿 好 '\n","                      '了 ︾ 老 师 ︑ 笑 了 笑 说 我 已 经 走 不 稳 了 呢 ？ 因 为 我 已 经 喝 得 很 多 了 '\n","                      '所 以 不 行 ︾ 我 一 脸 自 信 ︑ 稍 微 有 些 骄 傲 ？ 如 果 是 我 的 话 ︑ 没 问 题 '\n","                      '的 ︾ 我 静 静 微 笑 ︑ 我 … 不 会 醉 的 ︾ 老 师 笑 了 笑 说 看 啊 … 我 已 经 走 '\n","                      '不 稳 了 呢 ？ ★ 左 下 ▲ 近 距 离 ■ 我 借 用 老 师 的 肩 膀 ︑ 轻 柔 介 抱 … ︑ '\n","                      '老 师 请 在 床 上 ︑ 大 愉 快 休 息 ● 我 借 用 老 师 的 肩 膀 介 抱 主 人 公 主 向 '\n","                      '寝 室 的 床 前 去 ○ 在 介 抱 借 用 老 师 的 肩 膀 时 移 动 时 的 呼 吸 ︵ 即 兴 表 '\n","                      '演 五 秒 左 右 ︶ ● 声 音 ● 打 开 门 ●'}],\n"," 'created': 1728874954,\n"," 'id': 'cmpl-6108f898-db8e-41f2-8c8b-8c4e538b2dcc',\n"," 'model': './models/sakura-14b-qwen2.5-v1.0-iq4xs.gguf',\n"," 'object': 'text_completion',\n"," 'usage': {'completion_tokens': 512,\n","           'prompt_tokens': 1309,\n","           'total_tokens': 1821}}\n","\u001b[32m2024-10-14 03:03:14\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mutils.model[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Output generated in 40.25 seconds (12.72 tokens/s, 512 tokens, context 1309 tokens)\n","\u001b[32m2024-10-14 03:03:14\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m answer: prompt_token=1309 new_token=512 text='这 样 不 好 哦 会 导 致 营 养 不 均 今 天 晚 上 我 就 用 温 暖 的 手 做 出 来 劳 劳 老 师 在 完 成 之 前 需 要 一 些 时 间 请 老 师 在 里 面 的 床 上 休 息 一 会 儿 好 了 ︾ 老 师 ︑ 笑 了 笑 说 我 已 经 走 不 稳 了 呢 ？ 因 为 我 已 经 喝 得 很 多 了 所 以 不 行 ︾ 我 一 脸 自 信 ︑ 稍 微 有 些 骄 傲 ？ 如 果 是 我 的 话 ︑ 没 问 题 的 ︾ 我 静 静 微 笑 ︑ 我 … 不 会 醉 的 ︾ 老 师 笑 了 笑 说 看 啊 … 我 已 经 走 不 稳 了 呢 ？ ★ 左 下 ▲ 近 距 离 ■ 我 借 用 老 师 的 肩 膀 ︑ 轻 柔 介 抱 … ︑ 老 师 请 在 床 上 ︑ 大 愉 快 休 息 ● 我 借 用 老 师 的 肩 膀 介 抱 主 人 公 主 向 寝 室 的 床 前 去 ○ 在 介 抱 借 用 老 师 的 肩 膀 时 移 动 时 的 呼 吸 ︵ 即 兴 表 演 五 秒 左 右 ︶ ● 声 音 ● 打 开 门 ●' finish_reason='length'\n","Llama.generate: 90 prefix-match hit, remaining 177 prompt tokens to eval\n","\n","llama_print_timings:        load time =    1268.44 ms\n","llama_print_timings:      sample time =       8.73 ms /    43 runs   (    0.20 ms per token,  4927.24 tokens per second)\n","llama_print_timings: prompt eval time =     367.09 ms /   177 tokens (    2.07 ms per token,   482.17 tokens per second)\n","llama_print_timings:        eval time =    2776.82 ms /    42 runs   (   66.11 ms per token,    15.13 tokens per second)\n","llama_print_timings:       total time =    3197.50 ms /   219 tokens\n","{'choices': [{'finish_reason': 'stop',\n","              'index': 0,\n","              'logprobs': None,\n","              'text': '■\\u3000你似乎很辛苦地流了汗……看来你做了个相当可怕的梦呢……■\\u3000'\n","                      '没事的，冷静下来……没事的……来，这边请。晚餐已经准备好了。」'}],\n"," 'created': 1728874994,\n"," 'id': 'cmpl-1e8b5a8a-9a21-4c5e-a288-51dbee67b477',\n"," 'model': './models/sakura-14b-qwen2.5-v1.0-iq4xs.gguf',\n"," 'object': 'text_completion',\n"," 'usage': {'completion_tokens': 42, 'prompt_tokens': 267, 'total_tokens': 309}}\n","\u001b[32m2024-10-14 03:03:17\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mutils.model[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Output generated in 3.20 seconds (13.11 tokens/s, 42 tokens, context 267 tokens)\n","\u001b[32m2024-10-14 03:03:17\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m answer: prompt_token=267 new_token=42 text='■\\u3000你似乎很辛苦地流了汗……看来你做了个相当可怕的梦呢……■\\u3000没事的，冷静下来……没事的……来，这边请。晚餐已经准备好了。」' finish_reason='stop'\n","Llama.generate: 90 prefix-match hit, remaining 1219 prompt tokens to eval\n","\n","llama_print_timings:        load time =    1268.44 ms\n","llama_print_timings:      sample time =     106.31 ms /   512 runs   (    0.21 ms per token,  4816.33 tokens per second)\n","llama_print_timings: prompt eval time =    2408.46 ms /  1219 tokens (    1.98 ms per token,   506.13 tokens per second)\n","llama_print_timings:        eval time =   36478.23 ms /   511 runs   (   71.39 ms per token,    14.01 tokens per second)\n","llama_print_timings:       total time =   39914.08 ms /  1730 tokens\n","{'choices': [{'finish_reason': 'length',\n","              'index': 0,\n","              'logprobs': None,\n","              'text': '这 样 不 好 哦 会 导 致 营 养 不 均 今 天 晚 上 我 就 用 温 暖 的 手 做 出 来 劳 劳 '\n","                      '老 师 在 完 成 之 前 需 要 一 些 时 间 请 老 师 在 里 面 的 床 上 休 息 一 会 儿 好 '\n","                      '了 ︾ 老 师 ︑ 笑 了 笑 说 我 已 经 走 不 稳 了 呢 ？ 因 为 我 已 经 喝 得 很 多 了 '\n","                      '所 以 不 行 ︾ 我 一 脸 自 信 ︑ 稍 微 有 些 骄 傲 ？ 如 果 是 我 的 话 ︑ 没 问 题 '\n","                      '的 ︾ 我 静 静 微 笑 ︑ 我 … 不 会 醉 的 ︾ 老 师 笑 了 笑 说 看 啊 … 我 已 经 走 '\n","                      '不 稳 了 呢 ？ ★ 左 下 ▲ 近 距 离 ■ 我 借 用 老 师 的 肩 膀 ︑ 轻 柔 介 抱 … ︑ '\n","                      '老 师 请 在 床 上 ︑ 好 好 休 息 ● 我 借 用 老 师 的 肩 膳 介 抱 主 人 公 主 向 寝 '\n","                      '室 的 床 前 去 ○ 在 介 抱 借 用 老 师 的 肩 膳 时 的 呼 吸 ︵ 即 兴 表 演 五 秒 左 '\n","                      '右 ︶ ● 声 音 ● 打 开 门 ● 倒 在 床 上'}],\n"," 'created': 1728874997,\n"," 'id': 'cmpl-a46f9924-1458-42a3-86b1-758549402357',\n"," 'model': './models/sakura-14b-qwen2.5-v1.0-iq4xs.gguf',\n"," 'object': 'text_completion',\n"," 'usage': {'completion_tokens': 512,\n","           'prompt_tokens': 1309,\n","           'total_tokens': 1821}}\n","\u001b[32m2024-10-14 03:03:57\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mutils.model[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Output generated in 39.92 seconds (12.82 tokens/s, 512 tokens, context 1309 tokens)\n","\u001b[32m2024-10-14 03:03:57\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m answer: prompt_token=1309 new_token=512 text='这 样 不 好 哦 会 导 致 营 养 不 均 今 天 晚 上 我 就 用 温 暖 的 手 做 出 来 劳 劳 老 师 在 完 成 之 前 需 要 一 些 时 间 请 老 师 在 里 面 的 床 上 休 息 一 会 儿 好 了 ︾ 老 师 ︑ 笑 了 笑 说 我 已 经 走 不 稳 了 呢 ？ 因 为 我 已 经 喝 得 很 多 了 所 以 不 行 ︾ 我 一 脸 自 信 ︑ 稍 微 有 些 骄 傲 ？ 如 果 是 我 的 话 ︑ 没 问 题 的 ︾ 我 静 静 微 笑 ︑ 我 … 不 会 醉 的 ︾ 老 师 笑 了 笑 说 看 啊 … 我 已 经 走 不 稳 了 呢 ？ ★ 左 下 ▲ 近 距 离 ■ 我 借 用 老 师 的 肩 膀 ︑ 轻 柔 介 抱 … ︑ 老 师 请 在 床 上 ︑ 好 好 休 息 ● 我 借 用 老 师 的 肩 膳 介 抱 主 人 公 主 向 寝 室 的 床 前 去 ○ 在 介 抱 借 用 老 师 的 肩 膳 时 的 呼 吸 ︵ 即 兴 表 演 五 秒 左 右 ︶ ● 声 音 ● 打 开 门 ● 倒 在 床 上' finish_reason='length'\n","Llama.generate: 92 prefix-match hit, remaining 1213 prompt tokens to eval\n","\u001b[32m2024-10-14 03:03:59\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Incoming request api: http://b1b7-34-32-252-14.ngrok-free.app/v1/chat/completions\n","\u001b[32m2024-10-14 03:03:59\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m client: Address(host='127.0.0.1', port=55602)\n","\u001b[32m2024-10-14 03:03:59\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m translate: <|im_start|>system\n","你是一个轻小说翻译模型，可以流畅通顺地以日本轻小说的风格将日文翻译成简体中文，并联系上下文正确使用人称代词，不擅自添加原文中没有的代词。<|im_end|>\n","<|im_start|>user\n","将下面的日文文本翻译成中文：● 蝉 の 声 ︒ 坂 道 を 降 り る ⾜ ⾳   ★ 左 斜 め 前   ▲ 中 距 離   ■ 驚 い て 咄 嗟 に   先 ︑ ⽣ … ？   ● 近 づ い て く る ⾜ ⾳   ★ 左 斜 め 前   ▲ 通 常   ■ 少 し 興 奮 気 味 で 嬉 し そ う に   お 久 し ぶ り で す ︒ 先 ⽣   ★ 左 斜 め 前   ▲ 通 常   ↓  ︵ 移 動 ︶   ★ 正 ⾯   ▲ 通 常   ■ 微 笑 し な が ら   ど う し た ん で す か ？   そ の 顔   ま さ か … 私 の こ と ︑ 忘 れ ち た ん で す か ？   ■ 嬉 し そ う に   雁 夜 で す ︒ 雁 夜 千 織   ⾼ 校 の 時 以 来 で す か ら … 五 年 ぶ り く ら い で す か ね ？   ほ ら   美 術 部 で 絵 を 教 え て く だ さ た じ な い で す か   ■ 思 い 出 し て も ら え て 満 ⾜ そ う に   え え ︑ え え …  ■ ほ と 気 が 緩 ん だ 様 ⼦ で   や と 思 い 出 し て く れ ま し た か   私 ︑ こ の 近 く に 住 ん で い る ん で す   ⼤ 学 か ら 近 い の で   ■ 様 ⼦ を 伺 う 感 じ で   そ の 展 ⽰ 案 内 …  も し か し て   う ち の ⼤ 学 の 展 ⽰ ︑ ⾒ に ⾏ か れ た ん で す か ？   ■ 尊 敬 の 眼 差 し で   や ぱ り …  流 ⽯ は 美 術 教 師 で す ね   ■ 期 待 し て 嬉 し そ う に   来 年 は 私 も 展 ⽰ す る の で   是 ⾮ い ら し て く だ さ い   ■ 得 意 気 に   ふ ふ ︑ そ う で す よ   こ れ で も ち ん と 芸 ⼤ 三 回 ⽣ で す か ら   ■ 嬉 し そ う に   先 ⽣ が 絵 を 教 え て く だ さ た お か げ で す   ■ 思 い つ い た 様 ⼦ で   そ う だ ︑ こ ん な と こ ろ で ⽴ ち 話 も 何 で す し   ア ト リ エ に い ら し て く れ ま せ ん か ？   ■ 気 遣 う 様 ⼦ で   先 ⽣ ︑ 喘 息 も あ り ま す し   体 強 く な い ん で す か ら …  ● 主 ⼈ 公 の 返 答 イ メ ジ ﹁ よ く 覚 え て え る ね … ︒ 確 か に 今 ⽇ も 暑 い し ︑ そ の ⽅ が い い か も ね ﹂   ■ 相 槌   は い …  ■ 優 し く 誘 う イ メ ジ   こ こ か ら 歩 い て 直 ぐ で す   冷 た い ⻨ 茶 も あ り ま す よ   ■ 少 し い じ ら し そ う に   そ れ に … 私 ︑ 先 ⽣ に ま た 絵 を ⾒ て も ら い た い で す   ■ 嬉 し そ う に   あ は … あ り が と う ご ざ い ま す   で は ︑ ご 案 内 い た し ま す ね   ● ⾜ ⾳   ★ 左   ▲ 通 常   ■ 微 笑 し な が ら   今 ⽇ も 暑 い で す ね   夏 だ か ら 仕 ⽅ な い ん で す け ど   ■ 楽 し そ う に   そ う だ ︑ 美 術 部 は ど う で す か ？   ■ 少 し 得 意 気 で 会 話 を 盛 り 上 げ よ う と 冗 談 混 じ り に   私 の 後 輩 に な り そ う な ︑ 優 秀 で 才 能 溢 れ る ⼦ は い ま す か ？   ふ ふ … そ り ⼀ 年 浪 ⼈ と は い え 芸 ⼤ 合 格 し て ま す し ？   少 し く ら い ⾃ 慢 し た い じ な い で す か   ■ 驚 い て シ ク を 受 け る   え … 美 術 部 無 く な ち た ん で す か ？   そ う … で す か   ■ 驚 愕 し た 様 ⼦ で   え …  美 術 の 授 業 も 無 く な る ん で す か ？   じ あ ︑ 先 ⽣ は …  ■ 唖 然 と し て   転 任 て … そ ん な …  ■ 意 気 消 沈   …… ︒   ■ 静 か に ⾃ ら を 納 得 さ せ る よ う に   元 々 ⾳ 楽 と 選 択 制 で し た も ん ね   ■ 寂 し そ う に   … そ う か … 今 は そ ん な 感 じ な ん で す ね   美 術 の 授 業 ま で 無 く な る と は …  … ︑ ⾊ 々 変 わ ち う も の で す ね   ■ 苦 笑 い し て   あ は は ︑ な ん か し ん み り し ち い ま し た ね   ■ 話 題 を 変 え よ う と ち と ぎ こ ち な く   そ う い え ば 私 の こ と ︑ 本 当 に 誰 だ か わ か ら な か た ん で す か ？   ■ 少 し む と し て   も う …  ■ 不 服 そ う に   酷 い で す よ ︑ 先 ⽣   恩 師 に 忘 れ ら れ て い た な ん て ︑ 傷 つ い ち い ま す   ■ 納 得 し て 理 解 を ⽰ す が ︑ 少 し 寂 し そ う に   ま ︑ で も …  先 ⽣ は 毎 年 沢 ⼭ の 新 ⼊ ⽣ の 顔 を 覚 え な き い け な い で し う し   卒 業 し た ⽣ 徒 の こ と ︑ 覚 え て い る ⽅ が 難 し い で す よ ね   ■ ⾃ 分 の 髪 を 弄 り な が ら ︑ 独 り ⾔ を 呟 く よ う に   ⾒ た ⽬ も … 髪 が 結 構 伸 び ま し た し   癖 ⽑ だ て ︑ 今 は 矯 正 し て ま す   ■ 少 し 寂 し そ う に   先 ⽣ の 中 の 私 の 印 象 は   あ の 頃 の ま ま で す よ ね   ● 主 ⼈ 公 が ﹁ 雁 夜 さ ん は 雰 囲 気 が 変 わ た ﹂ と 返 答   ■ ⾸ を 傾 げ な が ら   雰 囲 気 … で す か ？   ● 主 ⼈ 公 が ﹁ 別 ⼈ み た い に ⼤ ⼈ び て た ﹂ と 返 答   ■ 苦 笑 し な が ら   別 ⼈ て …  そ れ ︑ 褒 め て る ん で す か ？   ● ⾜ を ⽌ め る   ■ 嘆 息   ふ ん …  ★ 正 ⾯   ▲ 通 常   ■ ⼝ 元 に ⼈ 差 し 指 を 当 て て ︑ 静 か に 諭 す よ う に ︒ こ こ の 台 詞 だ け ミ ス テ リ ア ス に   先 ⽣   ⼥ の ⼦ は 変 わ る ん で す よ   も う ⼆ ⼗ 歳 な ん で す か ら ︑ ⼤ ⼈ な ん で す   ■ 先 ほ ど ま で の 楽 し そ う な 空 気 に 戻 て   つ き ま し た よ   ● ⾨ を 開 け る ⾳   ★ 右 斜 め 前   ▲ 通 常   ■ 坦 々 と 説 明   こ こ ︑ 祖 ⽗ の 家 な ん で す け ど   偶 然 ︑ ⼤ 学 に 近 く て   在 学 中 は 私 が ⼆ 階 に 住 ま わ せ て も ら て い た ん で す   で も ⼆ 年 前 に 亡 く な て   今 は 私 ⼀ ⼈ で 暮 ら し て い ま す   ● 家 の 扉 を 開 け る ⾳   ■ 申 し 訳 な さ そ う に   少 し 物 が 多 い で す け ど ︑ ど う ぞ   ● ⾜ ⾳ ︵ 家 の 中 ︶   ■ 苦 笑 い し な が ら   壁 ︑ す ご い で す よ ね   絵 画 を 集 め る の が 祖 ⽗ の 趣 味 だ た ん で す け ど   家 中 の 壁 ⼀ ⾯ に 飾 る の は ち と 不 気 味 で す よ ね   ● 主 ⼈ 公 が ﹁ お ⾦ 持 ち の お 祖 ⽗ さ ん だ た ん だ ね ﹂ と 返 答   ■ 思 案 し て   う ん …  お ⾦ 持 ち ︑ か は … ど う で し う か   ■ ⾒ 下 し た よ う な 笑 み ︒ 闇 を 感 じ さ せ る 感 じ で   こ れ 全 部 レ プ リ カ な ん で す よ   ■ 興 味 な さ そ う に   本 ⼈ は 絵 を 飾 る の が 趣 味 で   本 物 か ど う か は ど う で も よ か た ん で す   偽 物 で も ︑ ⼿ の 届 く と こ ろ に あ れ ば 満 ⾜ で き る   そ ん な 感 じ な ん で す か ね   ● 部 屋 の 扉 を 開 け る   ★ 右 斜 め 前   ▲ 通 常   ■ ⾃ 信 満 々 で 嬉 し そ う に ︒ テ ン シ ン ⾼ め で   じ ん   こ こ が 私 の ア ト リ エ で す   ど う で す か   イ ン テ リ ア ︑ 結 構 こ だ わ て る ん で す よ   絵 を 描 い て い る と ⽬ が 疲 れ る の で   植 ⽊ 鉢 に 緑 を 沢 ⼭ 置 い て る ん で す   ■ 苦 笑 い し て   あ ︑ そ れ 全 部 造 花 で す よ   ■ ⾸ を 傾 げ て 思 案 す る が ︑ す ぐ に 興 味 を 無 く す 感 じ で   い や … 花 は な い か ら 造 草 … ？   ま ︑ 呼 び ⽅ は ど う で も い い で す ね   ■ 楽 し そ う に   普 段 は こ こ に 座 て   こ の イ ゼ ル に キ ン バ ス を ⽴ て て 描 い て い ま す   素 敵 で す よ ね ？   ■ 嬉 し そ う に   う ふ ふ ︑ よ か た … 気 に い て も ら え て   ■ ハ と し た 様 ⼦ で   あ … 飲 み 物 忘 れ て ま し た   ■ 申 し 訳 な さ そ う に   ご め ん な さ い … ⼈ が 来 る こ と が 滅 多 に な い も の で す か ら   ■ そ わ そ わ し た 様 ⼦ で 嬉 し そ う に 期 待 し て   そ う だ … ︑ 私 も う 成 ⼈ し て る の で   お 酒 飲 め る よ う に な た ん で す よ   ■ い じ ら し い 様 ⼦ で   少 し 早 い 時 間 で す け ど ⼀ 緒 に ど う で す か ？   ■ し み じ み と 胸 の 内 を 吐 露 す る   私 … 昔 の 思 い 出 話 を し な が ら ⼀ 杯 や る の が 夢 だ た ん で す   ■ い じ ら し い 様 ⼦ で   付 き 合 て … く れ ま せ ん か ？   ■ 嬉 し そ う に   あ り が と う ご ざ い ま す …  ● 時 間 経 過   ★ 正 ⾯   ▲ 通 常   ■ 楽 し そ う に   そ れ で 美 術 室 の 鍵 …  結 局 先 ⽣ の ポ ケ ト に ⼊ て た ん で す よ ね   ■ 頬 を 膨 ら ま せ る 感 じ で ︑ 可 愛 く 怒 る   ⼤ 変 だ た ん で す よ ？   鍵 が 無 く て 施 錠 で き な い と 帰 れ な い の で ︑ 焦 り ま し た …  ■ 嬉 し そ う に   ま ︑ 今 と な て は い い 思 い 出 で す   ■ お 酒 を 飲 む   ご く … ご く ︑ ご く ︑ は …  ■ し み じ み と   先 ⽣ に 絵 を ご 指 導 い た だ い た 三 年 間 …  本 当 に ⼤ 切 な ︑ か え が え の な い ⽇ 々 で し た   ■ 少 し 申 し 訳 な さ そ う に   そ う だ ︑ ま た 私 の 絵 を ⾒ て い た だ け な い で し う か ？   そ ろ そ ろ 課 題 を ⼀ 枚 仕 上 げ な い と い け な い ん で す け ど   構 図 で 悩 ん で い て …  ■ 嬉 し そ う に   は い … ま た 後 ⽇ で い い の で 是 ⾮   あ ︑ 先 ⽣ も 遠 慮 せ ず に ど ん ど ん 飲 ん で く だ さ い   お 注 ぎ し ま す ね …  ● ⽸ ビ ル を 開 け て グ ラ ス に 注 ぐ ⾳   ■ し み じ み と   で も … も う 五 年 も 経 ち た ん で す ね   時 間 の 流 れ て 早 い で す   ● そ ろ そ ろ 帰 ろ う ⽴ ち 上 が る 主 ⼈ 公   ★ 正 ⾯   下   ▲ 通 常   ■ 少 し 悲 し そ う に   あ れ … も う ︑ 帰 ら れ る ん で す か ？   ま だ ⼗ ⼋ 時 で す よ ？   晩 ご 飯 ご 馳 ⾛ し よ う と 思 て い た の で す が …  ■ し ん と し て   あ ︑ そ う で す よ ね …  今 は ご 家 庭 が あ り ま す も ん ね   ご め ん な さ い …  奥 さ ん が 待 て ま す も ん ね   ■ 嘆 息   …… ︒   ● 主 ⼈ 公 が ﹁ 実 は 最 近 … 家 で は ⾷ べ て な い ん だ け ど ね ﹂ と 返 答   ■ 意 外 そ う に   え … ？   ご 飯 お 家 で ⾷ べ な い ん で す か ？   ■ 不 思 議 そ う に   え と …  何 か … 喧 嘩 で も さ れ た の で す か ？   ● 主 ⼈ 公 が ﹁ ま ︑ ⾊ 々 と ね …  ﹂ と 濁 す 返 答   ■ ま だ 少 し 納 得 で き て い な い 様 ⼦ で   そ う ︑ で す か …  お し ど り 夫 婦 と 聞 い て い た の で …  ■ 気 ま ず そ う に   …… ︒   ■ 気 遣 う よ う に   ま ︑ 夫 婦 仲 に も ⾊ 々 あ り ま す よ ね   ■ ⾊ 々 な 悲 し い 変 化 を 割 り 切 ろ う と ︑ ⾃ ら を 納 得 さ せ る よ う に 無 理 に 明 る く   先 ⽣ が ご 結 婚 さ れ た の も 五 年 前 で し た し   美 術 の 授 業 も そ う で す け ど ︑ 五 年 も あ れ ば   何 も か も が 変 わ て し ま う な ん て …  よ く あ る こ と な の か も し れ ま せ ん ね   ● 千 織 も 椅 ⼦ か ら ⽴ ち 上 が る   ★ 正 ⾯   ▲ 通 常   ■ 励 ま す よ う に 明 る く   じ あ 先 ⽣ ︑ 尚 更 お 料 理 ⾷ べ て い て く だ さ い   ■ や さ し く 明 る く   最 近 外 ⾷ ば か り な ん で す よ ね ？   そ れ で は 栄 養 が 偏 て ダ メ で す よ   な の で 今 夜 は 私 が   温 か い ⼿ 料 理 で 先 ⽣ を 労 ち い ま す   出 来 上 が る ま で 少 し お 時 間 い た だ き ま す の で   よ か た ら 奥 の ベ ド で 休 ん で い て く だ さ い   ■ 苦 笑 い し な が ら   先 ⽣ ︑ フ ラ フ ラ で す よ ？   結 構 飲 み ま し た か ら ね   仕 ⽅ あ り ま せ ん   ■ ⾃ 信 満 々 に ︑ 少 し ド ヤ て   私 で す か ？   こ の と お り ︑ ⼤ 丈 夫 で す   ■ 静 か に 微 笑 し な が ら   私 … 酔 え な い ん で す   ■ 苦 笑 い し な が ら   ほ ら … ⾸ か く か く し て ま す よ ？   ★ 左   下   ▲ 近 距 離   ■ 肩 を 貸 し て ︑ や さ し く 介 抱   … ︑ さ …  先 ⽣ は ベ ド で ︑ ⼤ ⼈ し く 休 ん で い て く だ さ い   ● 肩 を 貸 し て 主 ⼈ 公 を 介 抱 し 寝 室 の ベ ド に 向 か う   ○ 介 抱 し て 肩 を 貸 し な が ら の 移 動 す る 時 の 息 遣 い ︵ ア ド リ ブ 5 秒 程 度 ︶   ● ⾜ ⾳   ● 扉 を 開 け る   ● ベ ド に 倒 れ る ⾳   ★ 正 ⾯   上   ▲ 近 距 離   ■ 嬉 し そ う に   晩 ご 飯 の ⽀ 度 が 出 来 ま し た ら ︑ 呼 び に き ま す ね   ■ 静 か に う と り し て   そ れ で は … お や す み な さ い   先 ︑ ⽣ …  ● 暗 転   ● 夢 を ⾒ て い る よ う な 印 象 に な る よ う に 軽 く エ コ あ り   ● 千 織 が 騎 乗 位 で 主 ⼈ 公 を 逆 レ イ プ し て い る   ★ 正 ⾯   ▲ 近 距 離   ■ 嬉 し そ う に 喘 ぐ   ん … ︑ は … は … ︑ は   あ ︑ あ … あ ︑ あ ん … は う ︑ う …  は ん ︑ ん … ん ふ … あ う ︑ う う ん   ■ 恍 惚 と し た 様 ⼦ で   せ ん ︑ せ … 気 持 ち ︑ い い … で す か ？   私 も … 気 持 ち ︑ い い … で す よ …  せ ん せ …  ● ⽬ を 覚 ま す   ★ 右 斜 め 前   上   ▲ 通 常   ■ き と ん と し た 様 ⼦ で   先 ⽣ … ？   せ ん ︑ せ ？   ど う し た ん で す か ？   横 に な ら れ る 前 よ り も ︑ お 顔 が 真 ⾚ じ な い で す か   ■ か ら か う よ う に 微 笑 ん で   も し か し て …  変 な 夢 で も ⾒ ま し た ？   ■ 相 ⼿ を 労 わ る よ う に   汗 も か い て ま す し …  余 程 ⼤ 変 な 夢 を ⾒ ら れ た ん で す ね …  ■ 落 ち 着 か せ る よ う に   ⼤ 丈 夫 で す よ …  ⼤ 丈 夫 …  さ ︑ こ ち ら に ど う ぞ   晩 ご 飯 の ご ⽤ 意 ︑ 出 来 て い ま す か ら<|im_end|>\n","<|im_start|>assistant\n","\n","\n","llama_print_timings:        load time =    1268.44 ms\n","llama_print_timings:      sample time =     107.86 ms /   512 runs   (    0.21 ms per token,  4746.76 tokens per second)\n","llama_print_timings: prompt eval time =    2399.26 ms /  1213 tokens (    1.98 ms per token,   505.57 tokens per second)\n","llama_print_timings:        eval time =   36395.65 ms /   511 runs   (   71.22 ms per token,    14.04 tokens per second)\n","llama_print_timings:       total time =   39859.34 ms /  1724 tokens\n","{'choices': [{'finish_reason': 'length',\n","              'index': 0,\n","              'logprobs': None,\n","              'text': '差 不 多 要 把 作 业 完 成 一 幅 了 但 是 在 烦 惭 构 图 …■ 好 像 很 开 心 … 请 '\n","                      '不 用 管 我 ︑ 先 生 也 不 用 管 我 请 继 续 喝 酒 我 来 给 您 倒 酒 …● 打 开 瓶 '\n","                      '子 倒 在 玻 璃 杯 里■ 声 音 响 起 来 … 已 经 过 了 五 年 了 时 间 过 得 真 快● 差 '\n","                      '不 多 要 回 去 了 主 人 公★ 正 面 下▲ 通 常■ 有 些 悲 伤 … 已 经︑ 要 回 去 了 吗 '\n","                      '？ 还 只 是 晚 上 八 点 呢 ？ 我 还 想 说 要 去 您 家 吃 晚 饭 的 …■ 沉 默︑ 是 呢 '\n","                      '… 现 在 有 家 人 了 呢 对 不 起 … 有 妻 子 在 等 着 您■ 叹 气……︒● 主 人 公﹁ 其 '\n","                      '实 最 近 … 在 家 里 没 有 吃 过 饭 哟 ﹂ 回 答■ 意 外 呢 …？ 在 家 里 没 有 吃 过 '\n","                      '饭 吗 ？■ 不 可 思 议 呢 … 是 … 是 因 为 有 什 么 原 因 而 争 执 了 吗 ？● 主 人 '\n","                      '公﹁ 具 ︑ 体 原 因 我 也 说 不 清 … ﹂ 回 答■ 还 是 有 些 无 法 接 受 的 样 子'}],\n"," 'created': 1728875037,\n"," 'id': 'cmpl-c1d8c06e-448f-4dac-ab86-9cb84599df16',\n"," 'model': './models/sakura-14b-qwen2.5-v1.0-iq4xs.gguf',\n"," 'object': 'text_completion',\n"," 'usage': {'completion_tokens': 512,\n","           'prompt_tokens': 1305,\n","           'total_tokens': 1817}}\n","\u001b[32m2024-10-14 03:04:37\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mutils.model[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Output generated in 39.87 seconds (12.84 tokens/s, 512 tokens, context 1305 tokens)\n","\u001b[32m2024-10-14 03:04:37\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m answer: prompt_token=1305 new_token=512 text='差 不 多 要 把 作 业 完 成 一 幅 了 但 是 在 烦 惭 构 图 …■ 好 像 很 开 心 … 请 不 用 管 我 ︑ 先 生 也 不 用 管 我 请 继 续 喝 酒 我 来 给 您 倒 酒 …● 打 开 瓶 子 倒 在 玻 璃 杯 里■ 声 音 响 起 来 … 已 经 过 了 五 年 了 时 间 过 得 真 快● 差 不 多 要 回 去 了 主 人 公★ 正 面 下▲ 通 常■ 有 些 悲 伤 … 已 经︑ 要 回 去 了 吗 ？ 还 只 是 晚 上 八 点 呢 ？ 我 还 想 说 要 去 您 家 吃 晚 饭 的 …■ 沉 默︑ 是 呢 … 现 在 有 家 人 了 呢 对 不 起 … 有 妻 子 在 等 着 您■ 叹 气……︒● 主 人 公﹁ 其 实 最 近 … 在 家 里 没 有 吃 过 饭 哟 ﹂ 回 答■ 意 外 呢 …？ 在 家 里 没 有 吃 过 饭 吗 ？■ 不 可 思 议 呢 … 是 … 是 因 为 有 什 么 原 因 而 争 执 了 吗 ？● 主 人 公﹁ 具 ︑ 体 原 因 我 也 说 不 清 … ﹂ 回 答■ 还 是 有 些 无 法 接 受 的 样 子' finish_reason='length'\n","Llama.generate: 90 prefix-match hit, remaining 1015 prompt tokens to eval\n","\n","llama_print_timings:        load time =    1268.44 ms\n","llama_print_timings:      sample time =     159.53 ms /   513 runs   (    0.31 ms per token,  3215.66 tokens per second)\n","llama_print_timings: prompt eval time =    1966.63 ms /  1015 tokens (    1.94 ms per token,   516.11 tokens per second)\n","llama_print_timings:        eval time =   36208.31 ms /   512 runs   (   70.72 ms per token,    14.14 tokens per second)\n","llama_print_timings:       total time =   40073.11 ms /  1527 tokens\n","{'choices': [{'finish_reason': 'length',\n","              'index': 0,\n","              'logprobs': None,\n","              'text': '真 ︑ 呼 ～ 呼 ～ 你 怎 么 说 都 行 哦 ■ 看 你 平 时 就 很 高 兴 地 坐 在 这 里 用 '\n","                      '铅 笔 在 素 材 上 画 着 画 素 材 画 真 是 有 意 思 呢 ？ ■ 看 你 平 时 就 很 高 兴 '\n","                      '地 呼 ～ 呼 ～ ︑ 太 好 了 … 你 感 兴 趣 了 呢 ■ 看 你 平 时 就 很 高 兴 地 像 受 '\n","                      '到 了 什 么 惊 喜 一 样 … 忘 记 了 带 饮 料 来 了 ■ 看 你 平 时 就 很 高 兴 地 像 '\n","                      '受 到 了 什 么 惊 喜 一 样 … 非 常 抱 歉 … 因 为 很 少 有 人 来 这 里 所 以 忘 记 '\n","                      '了 带 来 了 ■ 看 你 平 时 就 很 高 兴 地 像 受 到 了 什 么 惊 喜 一 样 … 虽 然 还 '\n","                      '是 早 上 但 要 不 要 来 一 杯 ？ ■ 看 你 平 时 就 很 高 兴 地 像 受 到 了 什 么 惊 '\n","                      '喜 一 样 … 我 也 已 经 成 年 了 所 以 已 经 可 以 喝 酒 了 哦 ■ 看 你 平 时 就 很 '\n","                      '高 兴 地 像 受 到 了 什 么 惊 喜 一 样 … 要 不 要'}],\n"," 'created': 1728875077,\n"," 'id': 'cmpl-6575e13c-22c4-4fe5-8a07-880051915dfc',\n"," 'model': './models/sakura-14b-qwen2.5-v1.0-iq4xs.gguf',\n"," 'object': 'text_completion',\n"," 'usage': {'completion_tokens': 513,\n","           'prompt_tokens': 1105,\n","           'total_tokens': 1618}}\n","\u001b[32m2024-10-14 03:05:17\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mutils.model[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Output generated in 40.08 seconds (12.80 tokens/s, 513 tokens, context 1105 tokens)\n","\u001b[32m2024-10-14 03:05:17\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m answer: prompt_token=1105 new_token=513 text='真 ︑ 呼 ～ 呼 ～ 你 怎 么 说 都 行 哦 ■ 看 你 平 时 就 很 高 兴 地 坐 在 这 里 用 铅 笔 在 素 材 上 画 着 画 素 材 画 真 是 有 意 思 呢 ？ ■ 看 你 平 时 就 很 高 兴 地 呼 ～ 呼 ～ ︑ 太 好 了 … 你 感 兴 趣 了 呢 ■ 看 你 平 时 就 很 高 兴 地 像 受 到 了 什 么 惊 喜 一 样 … 忘 记 了 带 饮 料 来 了 ■ 看 你 平 时 就 很 高 兴 地 像 受 到 了 什 么 惊 喜 一 样 … 非 常 抱 歉 … 因 为 很 少 有 人 来 这 里 所 以 忘 记 了 带 来 了 ■ 看 你 平 时 就 很 高 兴 地 像 受 到 了 什 么 惊 喜 一 样 … 虽 然 还 是 早 上 但 要 不 要 来 一 杯 ？ ■ 看 你 平 时 就 很 高 兴 地 像 受 到 了 什 么 惊 喜 一 样 … 我 也 已 经 成 年 了 所 以 已 经 可 以 喝 酒 了 哦 ■ 看 你 平 时 就 很 高 兴 地 像 受 到 了 什 么 惊 喜 一 样 … 要 不 要' finish_reason='stop'\n","Llama.generate: 89 prefix-match hit, remaining 1269 prompt tokens to eval\n","\n","llama_print_timings:        load time =    1268.44 ms\n","llama_print_timings:      sample time =     102.42 ms /   309 runs   (    0.33 ms per token,  3016.84 tokens per second)\n","llama_print_timings: prompt eval time =    2521.61 ms /  1269 tokens (    1.99 ms per token,   503.25 tokens per second)\n","llama_print_timings:        eval time =   22172.85 ms /   308 runs   (   71.99 ms per token,    13.89 tokens per second)\n","llama_print_timings:       total time =   25916.68 ms /  1577 tokens\n","{'choices': [{'finish_reason': 'stop',\n","              'index': 0,\n","              'logprobs': None,\n","              'text': '●叹气■呼……★正脸▲通常■用食指抵住嘴边︑静静地劝告︒只有这句台词让神秘推理的先生成了另一个人，真是的，都已经二十岁了︑已经是大人了■恢复到刚才为止的愉快气氛●打开门★右斜前方▲通常■坦然地说明︑虽然是祖父的家，但因为离大学很近，所以在学期间我住在二楼，但祖父两年前去世了，现在只有我一个人住●打开家门■抱歉，东西有点多︑请进●叹气︵在家里面︶■苦笑着看着墙壁︑很厉害吧，祖父的兴趣是收集绘画，但把画挂在家中的一面墙上，有点可怕呢●主人公「﹁祖父是很有钱的人吧﹂」回答■思考……有钱吗……？■露出轻视的笑容︒让人感觉到黑暗，这些全部都是复制品■不感兴趣，本人的兴趣是装饰绘画，是不是真品都无所谓，就算是赝品︑只要放在手边就能满足，就是这种感觉吧●打开房间的门★右斜前方▲通常■自信满满，很开心︒心情很好，这里是我的工作室，怎么样，很时尚吧︑很讲究结构哦，画画的时候眼睛会疲劳，所以放了植物盆栽来增加绿意■苦笑︑那些全部都是人造花■歪着头思考︑但很快就失去了兴趣，哎……没有花，所以是人造草……？\\n'}],\n"," 'created': 1728875117,\n"," 'id': 'cmpl-84b2be78-5561-444e-b074-a8c40eda63ed',\n"," 'model': './models/sakura-14b-qwen2.5-v1.0-iq4xs.gguf',\n"," 'object': 'text_completion',\n"," 'usage': {'completion_tokens': 308,\n","           'prompt_tokens': 1358,\n","           'total_tokens': 1666}}\n","\u001b[32m2024-10-14 03:05:43\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mutils.model[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Output generated in 25.95 seconds (11.87 tokens/s, 308 tokens, context 1358 tokens)\n","\u001b[32m2024-10-14 03:05:43\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m answer: prompt_token=1358 new_token=308 text='●叹气■呼……★正脸▲通常■用食指抵住嘴边︑静静地劝告︒只有这句台词让神秘推理的先生成了另一个人，真是的，都已经二十岁了︑已经是大人了■恢复到刚才为止的愉快气氛●打开门★右斜前方▲通常■坦然地说明︑虽然是祖父的家，但因为离大学很近，所以在学期间我住在二楼，但祖父两年前去世了，现在只有我一个人住●打开家门■抱歉，东西有点多︑请进●叹气︵在家里面︶■苦笑着看着墙壁︑很厉害吧，祖父的兴趣是收集绘画，但把画挂在家中的一面墙上，有点可怕呢●主人公「﹁祖父是很有钱的人吧﹂」回答■思考……有钱吗……？■露出轻视的笑容︒让人感觉到黑暗，这些全部都是复制品■不感兴趣，本人的兴趣是装饰绘画，是不是真品都无所谓，就算是赝品︑只要放在手边就能满足，就是这种感觉吧●打开房间的门★右斜前方▲通常■自信满满，很开心︒心情很好，这里是我的工作室，怎么样，很时尚吧︑很讲究结构哦，画画的时候眼睛会疲劳，所以放了植物盆栽来增加绿意■苦笑︑那些全部都是人造花■歪着头思考︑但很快就失去了兴趣，哎……没有花，所以是人造草……？\\n' finish_reason='stop'\n","Llama.generate: 89 prefix-match hit, remaining 593 prompt tokens to eval\n","\n","llama_print_timings:        load time =    1268.44 ms\n","llama_print_timings:      sample time =     221.32 ms /   513 runs   (    0.43 ms per token,  2317.88 tokens per second)\n","llama_print_timings: prompt eval time =    1169.46 ms /   593 tokens (    1.97 ms per token,   507.07 tokens per second)\n","llama_print_timings:        eval time =   36096.82 ms /   512 runs   (   70.50 ms per token,    14.18 tokens per second)\n","llama_print_timings:       total time =   39641.46 ms /  1105 tokens\n","{'choices': [{'finish_reason': 'length',\n","              'index': 0,\n","              'logprobs': None,\n","              'text': '■ 稍 微 冷 静 一 点 吧 … ■ 不 服 气 似 的 太 残 忍 了 哦 ︑ 被 师 父 忘 记 了 ︑ '\n","                      '真 是 伤 心 ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ '\n","                      '︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ '\n","                      '︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ '\n","                      '︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ '\n","                      '︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ '\n","                      '︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑'}],\n"," 'created': 1728875143,\n"," 'id': 'cmpl-55be63f5-34a0-46f4-80bd-e7a6f1b552a2',\n"," 'model': './models/sakura-14b-qwen2.5-v1.0-iq4xs.gguf',\n"," 'object': 'text_completion',\n"," 'usage': {'completion_tokens': 513,\n","           'prompt_tokens': 682,\n","           'total_tokens': 1195}}\n","\u001b[32m2024-10-14 03:06:23\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mutils.model[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Output generated in 39.66 seconds (12.94 tokens/s, 513 tokens, context 682 tokens)\n","\u001b[32m2024-10-14 03:06:23\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m answer: prompt_token=682 new_token=513 text='■ 稍 微 冷 静 一 点 吧 … ■ 不 服 气 似 的 太 残 忍 了 哦 ︑ 被 师 父 忘 记 了 ︑ 真 是 伤 心 ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑ ︑' finish_reason='stop'\n","Llama.generate: 3 prefix-match hit, remaining 96 prompt tokens to eval\n","\n","llama_print_timings:        load time =    1268.44 ms\n","llama_print_timings:      sample time =       5.77 ms /    26 runs   (    0.22 ms per token,  4509.19 tokens per second)\n","llama_print_timings: prompt eval time =     260.01 ms /    96 tokens (    2.71 ms per token,   369.22 tokens per second)\n","llama_print_timings:        eval time =    1644.29 ms /    25 runs   (   65.77 ms per token,    15.20 tokens per second)\n","llama_print_timings:       total time =    1987.91 ms /   121 tokens\n","{'choices': [{'finish_reason': 'stop',\n","              'index': 0,\n","              'logprobs': None,\n","              'text': '穿过国境的长长隧道之后，就是雪国了。夜的底部开始泛白。火车停在车站。'}],\n"," 'created': 1728875183,\n"," 'id': 'cmpl-caace05a-4cbf-45d7-a3b7-ceedd591200c',\n"," 'model': './models/sakura-14b-qwen2.5-v1.0-iq4xs.gguf',\n"," 'object': 'text_completion',\n"," 'usage': {'completion_tokens': 25, 'prompt_tokens': 99, 'total_tokens': 124}}\n","\u001b[32m2024-10-14 03:06:25\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mutils.model[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m Output generated in 2.01 seconds (12.44 tokens/s, 25 tokens, context 99 tokens)\n","\u001b[32m2024-10-14 03:06:25\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mapi.openai.v1.chat[4104]\u001b[0m \u001b[1;30mINFO\u001b[0m answer: prompt_token=99 new_token=25 text='穿过国境的长长隧道之后，就是雪国了。夜的底部开始泛白。火车停在车站。' finish_reason='stop'\n","[2024-10-14 03:06:25 +0000] [4104] [ERROR] Error in ASGI Framework\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/hypercorn/asyncio/task_group.py\", line 27, in _handle\n","    await app(scope, receive, send, sync_spawn, call_soon)\n","  File \"/usr/local/lib/python3.10/dist-packages/hypercorn/app_wrappers.py\", line 34, in __call__\n","    await self.app(scope, receive, send)\n","  File \"/usr/local/lib/python3.10/dist-packages/fastapi/applications.py\", line 1054, in __call__\n","    await super().__call__(scope, receive, send)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/applications.py\", line 113, in __call__\n","    await self.middleware_stack(scope, receive, send)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/errors.py\", line 187, in __call__\n","    raise exc\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/errors.py\", line 165, in __call__\n","    await self.app(scope, receive, _send)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/cors.py\", line 93, in __call__\n","    await self.simple_response(scope, receive, send, request_headers=headers)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/cors.py\", line 144, in simple_response\n","    await self.app(scope, receive, send)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n","    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n","    raise exc\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n","    await app(scope, receive, sender)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 715, in __call__\n","    await self.middleware_stack(scope, receive, send)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 735, in app\n","    await route.handle(scope, receive, send)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 288, in handle\n","    await self.app(scope, receive, send)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 76, in app\n","    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n","    raise exc\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n","    await app(scope, receive, sender)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 73, in app\n","    response = await f(request)\n","  File \"/usr/local/lib/python3.10/dist-packages/fastapi/routing.py\", line 301, in app\n","    raw_response = await run_endpoint_function(\n","  File \"/usr/local/lib/python3.10/dist-packages/fastapi/routing.py\", line 214, in run_endpoint_function\n","    return await run_in_threadpool(dependant.call, **values)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/concurrency.py\", line 39, in run_in_threadpool\n","    return await anyio.to_thread.run_sync(func, *args)\n","  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n","    return await get_asynclib().run_sync_in_worker_thread(\n","  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n","    return await future\n","  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n","    result = context.run(func, *args)\n","  File \"/content/gdrive/MyDrive/Sakura-13B-Galgame/api/openai/v1/chat.py\", line 147, in completions\n","    ret = get_output(data)\n","  File \"/content/gdrive/MyDrive/Sakura-13B-Galgame/api/openai/v1/chat.py\", line 33, in get_output\n","    output = model.completion(prompt, generation_config)\n","  File \"/content/gdrive/MyDrive/Sakura-13B-Galgame/utils/model.py\", line 287, in completion\n","    output = self.__get_model_response(\n","  File \"/content/gdrive/MyDrive/Sakura-13B-Galgame/utils/model.py\", line 333, in __get_model_response\n","    output, (input_tokens_len, new_tokens) = model.generate(prompt, generation_config)\n","  File \"/content/gdrive/MyDrive/Sakura-13B-Galgame/infers/llama.py\", line 40, in generate\n","    output = self.model(prompt, max_tokens=generation_config.__dict__['max_new_tokens'],\n","  File \"/usr/local/lib/python3.10/dist-packages/llama_cpp/llama.py\", line 1799, in __call__\n","    return self.create_completion(\n","  File \"/usr/local/lib/python3.10/dist-packages/llama_cpp/llama.py\", line 1732, in create_completion\n","    completion: Completion = next(completion_or_chunks)  # type: ignore\n","  File \"/usr/local/lib/python3.10/dist-packages/llama_cpp/llama.py\", line 1169, in _create_completion\n","    raise ValueError(\n","ValueError: Requested tokens (7906) exceed context window of 2048\n","\u001b[32m2024-10-14 03:06:25\u001b[0m \u001b[35mf214cf4a48b0\u001b[0m \u001b[34mhypercorn.error[4104]\u001b[0m \u001b[1;30mERROR\u001b[0m \u001b[31mError in ASGI Framework\u001b[0m\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/hypercorn/asyncio/task_group.py\", line 27, in _handle\n","    await app(scope, receive, send, sync_spawn, call_soon)\n","  File \"/usr/local/lib/python3.10/dist-packages/hypercorn/app_wrappers.py\", line 34, in __call__\n","    await self.app(scope, receive, send)\n","  File \"/usr/local/lib/python3.10/dist-packages/fastapi/applications.py\", line 1054, in __call__\n","    await super().__call__(scope, receive, send)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/applications.py\", line 113, in __call__\n","    await self.middleware_stack(scope, receive, send)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/errors.py\", line 187, in __call__\n","    raise exc\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/errors.py\", line 165, in __call__\n","    await self.app(scope, receive, _send)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/cors.py\", line 93, in __call__\n","    await self.simple_response(scope, receive, send, request_headers=headers)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/cors.py\", line 144, in simple_response\n","    await self.app(scope, receive, send)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n","    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n","    raise exc\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n","    await app(scope, receive, sender)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 715, in __call__\n","    await self.middleware_stack(scope, receive, send)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 735, in app\n","    await route.handle(scope, receive, send)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 288, in handle\n","    await self.app(scope, receive, send)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 76, in app\n","    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/_exception_handler.py\", line 62, in wrapped_app\n","    raise exc\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/_exception_handler.py\", line 51, in wrapped_app\n","    await app(scope, receive, sender)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 73, in app\n","    response = await f(request)\n","  File \"/usr/local/lib/python3.10/dist-packages/fastapi/routing.py\", line 301, in app\n","    raw_response = await run_endpoint_function(\n","  File \"/usr/local/lib/python3.10/dist-packages/fastapi/routing.py\", line 214, in run_endpoint_function\n","    return await run_in_threadpool(dependant.call, **values)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/concurrency.py\", line 39, in run_in_threadpool\n","    return await anyio.to_thread.run_sync(func, *args)\n","  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n","    return await get_asynclib().run_sync_in_worker_thread(\n","  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n","    return await future\n","  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n","    result = context.run(func, *args)\n","  File \"/content/gdrive/MyDrive/Sakura-13B-Galgame/api/openai/v1/chat.py\", line 147, in completions\n","    ret = get_output(data)\n","  File \"/content/gdrive/MyDrive/Sakura-13B-Galgame/api/openai/v1/chat.py\", line 33, in get_output\n","    output = model.completion(prompt, generation_config)\n","  File \"/content/gdrive/MyDrive/Sakura-13B-Galgame/utils/model.py\", line 287, in completion\n","    output = self.__get_model_response(\n","  File \"/content/gdrive/MyDrive/Sakura-13B-Galgame/utils/model.py\", line 333, in __get_model_response\n","    output, (input_tokens_len, new_tokens) = model.generate(prompt, generation_config)\n","  File \"/content/gdrive/MyDrive/Sakura-13B-Galgame/infers/llama.py\", line 40, in generate\n","    output = self.model(prompt, max_tokens=generation_config.__dict__['max_new_tokens'],\n","  File \"/usr/local/lib/python3.10/dist-packages/llama_cpp/llama.py\", line 1799, in __call__\n","    return self.create_completion(\n","  File \"/usr/local/lib/python3.10/dist-packages/llama_cpp/llama.py\", line 1732, in create_completion\n","    completion: Completion = next(completion_or_chunks)  # type: ignore\n","  File \"/usr/local/lib/python3.10/dist-packages/llama_cpp/llama.py\", line 1169, in _create_completion\n","    raise ValueError(\n","ValueError: Requested tokens (7906) exceed context window of 2048\n","Exception ignored in: <function Llama.__del__ at 0x7cad24865120>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/llama_cpp/llama.py\", line 2099, in __del__\n","  File \"/usr/local/lib/python3.10/dist-packages/llama_cpp/llama.py\", line 2096, in close\n","  File \"/usr/lib/python3.10/contextlib.py\", line 584, in close\n","  File \"/usr/lib/python3.10/contextlib.py\", line 576, in __exit__\n","  File \"/usr/lib/python3.10/contextlib.py\", line 561, in __exit__\n","  File \"/usr/lib/python3.10/contextlib.py\", line 340, in __exit__\n","  File \"/usr/local/lib/python3.10/dist-packages/llama_cpp/_internals.py\", line 66, in close\n","  File \"/usr/lib/python3.10/contextlib.py\", line 584, in close\n","  File \"/usr/lib/python3.10/contextlib.py\", line 576, in __exit__\n","  File \"/usr/lib/python3.10/contextlib.py\", line 561, in __exit__\n","  File \"/usr/lib/python3.10/contextlib.py\", line 449, in _exit_wrapper\n","  File \"/usr/local/lib/python3.10/dist-packages/llama_cpp/_internals.py\", line 60, in free_model\n","TypeError: 'NoneType' object is not callable\n","^C\n"]}]},{"cell_type":"code","source":["#@title 内网穿透\n","from pyngrok import ngrok\n","\n","# 设置 ngrok authtoken（替换 <YOUR_AUTH_TOKEN> 为你的实际 ngrok authtoken）\n","!ngrok authtoken 2aD0E5ADxy6miRBapzrwWTOu3j6_3Phqsv4LxCQwu7iVuxYgT\n","\n","# 启动 ngrok 隧道并连接到本地端口 8080\n","public_url = ngrok.connect(8080)\n","print(\"ngrok tunnel URL:\", public_url)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hIjlxWlYLv7n","executionInfo":{"status":"ok","timestamp":1728229227430,"user_tz":-480,"elapsed":1331,"user":{"displayName":"cymhh nory","userId":"17474100186628747229"}},"outputId":"c7d00ebe-f8d1-4c9f-ab0a-9ab0d413705e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n","ngrok tunnel URL: NgrokTunnel: \"https://fabf-34-143-208-132.ngrok-free.app\" -> \"http://localhost:8080\"\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/Isotr0py/SakuraLLM-Notebooks/blob/main/Sakura-13B-Galgame-Colab.ipynb","timestamp":1728220707358}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ec033522552e415eaf87df12de29c6fe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_638be34d74e84a04a38e26cad1b7e1a7","IPY_MODEL_7cfa9c1029a34a8fbf6fa7ad8b1c9c73","IPY_MODEL_0a77d7d559a74321978a5978a783aabd"],"layout":"IPY_MODEL_f96562bd63824eb0acbd627714f3e7f1"}},"638be34d74e84a04a38e26cad1b7e1a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_865133b617a24f67a5228e7fa1f35b39","placeholder":"​","style":"IPY_MODEL_770337bb59e84bd89ee3f7691c03ec86","value":"sakura-14b-qwen2.5-v1.0-iq4xs.gguf: 100%"}},"7cfa9c1029a34a8fbf6fa7ad8b1c9c73":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4be1702e36db4b29a9d592237a3429ff","max":8186195264,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5dad1d7db0504a379e1a258bc885a3ce","value":8186195264}},"0a77d7d559a74321978a5978a783aabd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4999120da8bf484a80c278a7fe240721","placeholder":"​","style":"IPY_MODEL_629e4d4cbf584661bd43f78ab1200b42","value":" 8.19G/8.19G [00:26&lt;00:00, 192MB/s]"}},"f96562bd63824eb0acbd627714f3e7f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"865133b617a24f67a5228e7fa1f35b39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"770337bb59e84bd89ee3f7691c03ec86":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4be1702e36db4b29a9d592237a3429ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5dad1d7db0504a379e1a258bc885a3ce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4999120da8bf484a80c278a7fe240721":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"629e4d4cbf584661bd43f78ab1200b42":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}